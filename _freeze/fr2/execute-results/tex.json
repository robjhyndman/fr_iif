{
  "hash": "fdf8795704b54af0cd9268d2b3ae25e4",
  "result": {
    "markdown": "---\ntitle: Forecast reconciliation\nsubtitle: 2. Perspectives on forecast reconciliation\nauthor: Rob J Hyndman\npdf-engine: latexmk\nfig-width: 9\nfig-height: 4.5\nformat:\n  beamer:\n    theme: monash\n    aspectratio: 169\n    fontsize: 14pt\n    section-titles: false\n    knitr:\n      opts_chunk:\n        dev: \"CairoPDF\"\ninclude-in-header: header.tex\ncite-method: biblatex\nbibliography: hts.bib\nbiblio-title: References\nhighlight-style: tango\nkeep-tex: true\nexecute:\n  echo: false\n  message: false\n  warning: false\n  cache: true\n---\n\n::: {.cell}\n\n:::\n\n\n## Outline\n\n\\vspace*{0.7cm}\\tableofcontents\n\n# Time series reconciliation\n\n## Time series reconciliation\n\\fontsize{13}{15}\\sf\n\n* @Stone1942: reconciling national economic accounts (disaggregated into production, income, outlay, capital transactions, etc.)\n* @Byron1978: extended Stone's work using more computationally efficient methods.\n* 1984: Stone wins Nobel Prize in Economics.\n* Same approach used for reconciling seasonally adjusted data.\n* @chow1971best: Temporal reconciliation of monthly or quarterly estimates to sum to annual estimates.\n* @Di_Fonzo1990: Cross-temporal reconciliation of time series data.\n\n# Reconciliation via constraints\n\n## Notation reminder\n\n\\begin{textblock}{8.5}(0.2,1.5)\nEvery collection of time series with linear constraints can be written as\n\\centerline{\\colorbox[RGB]{210,210,210}{$\\bY_{t}=\\color{blue}\\bS\\color{red}\\bm{b}_{t}$}}\n\\vspace*{-0.9cm}\\begin{itemize}\\parskip=0cm\\itemsep=0cm\n\\item $\\by_t=$ vector of all series at time $t$\n\\item $ y_{\\text{Total},t}= $ aggregate of all series at time\n$t$.\n\\item $ y_{X,t}= $ value of series $X$ at time $t$.\n\\item $\\color{red}{\\bm{b}_t}=$ vector of most disaggregated series at time $t$\n\\item $\\color{blue}{\\bS}=$ ``summing matrix'' containing the linear constraints.\n\\end{itemize}\n\\end{textblock}\n\n\\begin{textblock}{5.7}(11.4,0.1)\n\\begin{minipage}{4cm}\n\\begin{block}{}\\centering\n\\begin{tikzpicture}\n\\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]\n\\tikzstyle[level distance=.3cm]\n\\tikzstyle[sibling distance=12cm]\n\\tikzstyle{level 1}=[sibling distance=10mm,font=\\small,set style={{every node}+=[fill=blue!15]}]\n\\node{Total}[edge from parent fork down]\n child {node {A}\n }\n child {node {B}\n }\n child {node {C}\n };\n\\end{tikzpicture}\n\\end{block}\n\\end{minipage}\n\\end{textblock}\n\n\\only<1>{\\begin{textblock}{5.7}(9.4,2.8)\\fontsize{14}{15}\\sf\n\\begin{align*}\n\\bY_{t}&= \\begin{pmatrix}\n  y_{\\text{Total},t}\\\\\n  y_{A,t}\\\\\n  y_{B,t}\\\\\n  y_{C,t}\n  \\end{pmatrix}  \\\\\n  &= {\\color{blue}\\underbrace{\\begin{pmatrix}\n                1 & 1 & 1 \\\\\n                1 & 0 & 0 \\\\\n                0 & 1 & 0\\\\\n                0 & 0 & 1\n                \\end{pmatrix}}_{\\bS}}\n     {\\color{red}\\underbrace{\\begin{pmatrix}\n       y_{A,t}\\\\y_{B,t}\\\\y_{C,t}\n       \\end{pmatrix}}_{\\bm{b}_{t}}}\n\\end{align*}\n\\end{textblock}}\n\\only<2>{\\begin{textblock}{5.7}(9.4,3.2)\\fontsize{14}{15}\\sf\n\\begin{alertblock}{}\n\\begin{itemize}\\itemsep=0.1cm\n\\item Base forecasts: $\\hat{\\bm{y}}_{T+h|T}$\n\\item Reconciled forecasts: $\\tilde{\\bm{y}}_{T+h|T}=\\bS\\bm{G}\\hat{\\bm{y}}_{T+h|T}$\n\\item MinT: $\\bG = (\\bS'\\bm{W}_h^{-1}\\bS)^{-1}\\bS'\\bm{W}_h^{-1}$ where $\\bm{W}_h$ is covariance matrix of base forecast errors.\n\\end{itemize}\n\\end{alertblock}\n\\end{textblock}}\n\n## Notation\n\n\\begin{textblock}{5.7}(11.4,0.1)\n\\begin{minipage}{4cm}\n\\begin{block}{}\\centering\n\\begin{tikzpicture}\n\\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]\n\\tikzstyle[level distance=.3cm]\n\\tikzstyle[sibling distance=12cm]\n\\tikzstyle{level 1}=[sibling distance=10mm,font=\\small,set style={{every node}+=[fill=blue!15]}]\n\\node{Total}[edge from parent fork down]\n child {node {A}\n }\n child {node {B}\n }\n child {node {C}\n };\n\\end{tikzpicture}\n\\end{block}\n\\end{minipage}\n\\end{textblock}\n\n\\begin{textblock}{6}(0.5,1.5)\n\\begin{block}{Aggregation matrix}\\vspace*{-0.6cm}\n\\begin{align*}\n\\bY_{t} & =\\color{blue}\\bS\\color{red}\\bm{b}_{t} \\\\[0.3cm]\n\\begin{pmatrix}\n   \\textcolor{DarkYellow}{y_{\\text{Total},t}}\\\\\n   \\textcolor{red}{y_{A,t}}\\\\\n   \\textcolor{red}{y_{B,t}}\\\\\n   \\textcolor{red}{y_{C,t}}\n  \\end{pmatrix}\n  &= {\\color{blue}\\begin{pmatrix}\n                \\textcolor{DarkYellow}1 & \\textcolor{DarkYellow}1 & \\textcolor{DarkYellow}1 \\\\\n                1 & 0 & 0 \\\\\n                0 & 1 & 0\\\\\n                0 & 0 & 1\n                \\end{pmatrix}}\n     {\\color{red}\\begin{pmatrix}\n       y_{A,t}\\\\y_{B,t}\\\\y_{C,t}\n       \\end{pmatrix}} \\\\[0.2cm]\n  \\begin{pmatrix}\\textcolor{DarkYellow}{\\bm{a}_t}\\\\\\textcolor{red}{\\bm{b}_t}\\end{pmatrix}\n   & = \\begin{pmatrix}\\textcolor{DarkYellow}{\\bm{A}}\\\\\\bm{I}_{n_b}\\end{pmatrix}\\textcolor{red}{\\bm{b}_t}\n\\end{align*}\n\\end{block}\n\\end{textblock}\n\n\\begin{textblock}{7}(8.1,3.5)\n\\begin{block}{Constraint matrix}\\vspace*{-0.6cm}\n\\begin{align*}\n\\bm{C} \\bY_t & = \\bm{0} \\\\\n\\text{where}\\qquad\n\\bm{C} & =  \\begin{bmatrix} 1 & -1 & -1 & -1 \\end{bmatrix} \\\\\n  & = \\begin{bmatrix} \\bm{I}_{n_a} & -\\textcolor{DarkYellow}{\\bm{A}} \\end{bmatrix}\n\\end{align*}\n\\end{block}\n\\end{textblock}\n\n\n## Zero-constraint representation\n\\vspace*{0.2cm}\n\n\\begin{block}{Aggregation matrix $\\bm{A}$}\n$$\\bm{y}_t\n    = \\begin{bmatrix}\\bm{a}_t\\\\\\bm{b}_t\\end{bmatrix}\n    = \\begin{bmatrix}\\bm{A}\\\\\\bm{I}_{n_b}\\end{bmatrix}\\bm{b}_t\n    = \\bm{S}\\bm{b}_t\n$$\n\\end{block}\\pause\n\n\\begin{block}{Constraint matrix $\\bm{C}$}\n\\centerline{$\\bm{C}\\bm{y}_t = \\bm{0}$}\n\\end{block}\\vspace*{-0.3cm}\n\n* Constraint matrix approach more general & more parsimonious.\n* $\\bm{C} = [\\bm{I}_{n_a} ~~~ {-\\bm{A}}]$.\n* $\\bm{S}$, $\\bm{A}$ and $\\bm{C}$ may contain any real values (not just 0s and 1s).\n\n## Zero-constraint representation\n\nAssuming $\\bm{C}$ is full rank\n\\begin{block}{}\n\\centerline{$\\tilde{\\bm{y}}_{T+h|T} = \\bm{M}\\hat{\\bm{y}}_{T+h|T}$}\n\\centerline{where\\qquad $\\bm{M} = \\bm{I} - \\bm{W}_h\\bm{C}'(\\bm{C}\\bm{W}_h\\bm{C}')^{-1}\\bm{C}$}\n\\end{block}\\vspace*{-0.3cm}\n\n* Originally proved by @Byron1978 for reconciling data.\n* Re-discovered by @mint for reconciling forecasts.\n* $\\bm{M} = \\bm{S}\\bm{G}$ (the MinT solution)\n* Leads to more efficient reconciliation than using $\\bm{G}$.\n\n## Zero-constraint representation\n\n\\begin{textblock}{5.7}(11.4,0.1)\n\\begin{minipage}{4cm}\n\\begin{block}{}\\centering\n\\begin{tikzpicture}\n\\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]\n\\tikzstyle[level distance=.3cm]\n\\tikzstyle[sibling distance=12cm]\n\\tikzstyle{level 1}=[sibling distance=10mm,font=\\small,set style={{every node}+=[fill=blue!15]}]\n\\node{Total}[edge from parent fork down]\n child {node {A}\n }\n child {node {B}\n }\n child {node {C}\n };\n\\end{tikzpicture}\n\\end{block}\n\\end{minipage}\n\\end{textblock}\n\n\\begin{textblock}{5.8}(9.6,3.5)\n\\begin{block}{}\\vspace*{-0.6cm}\\fontsize{11}{11}\\sf\n\\begin{align*}\n\\bm{A} &= \\begin{pmatrix}\n           1 & 1 & 1\n           \\end{pmatrix} \\\\\n\\bS & = \\begin{pmatrix}\\bm{A}\\\\\\bm{I}_{n_b}\\end{pmatrix} =\n\\begin{pmatrix}\n                1 & 1 & 1 \\\\\n                1 & 0 & 0 \\\\\n                0 & 1 & 0\\\\\n                0 & 0 & 1\n                \\end{pmatrix} \\\\\n\\bm{C} & = \\begin{pmatrix} \\bm{I}_{n_a} & - \\bm{A} \\end{pmatrix} = \\begin{pmatrix} 1 & -1 & -1 & -1 \\end{pmatrix}\n\\end{align*}\n\\end{block}\n\\end{textblock}\n\n\\begin{textblock}{9}(.2, 1.5)\\fontsize{11}{11}\\sf\nSuppose $\\bm{W}_h = \\bm{I}$. Then\\vspace*{-0.2cm}\n\\begin{align*}\n\\bm{M} &= \\bm{I} - \\bm{W}_h\\bm{C}'(\\bm{C}\\bm{W}_h\\bm{C}')^{-1}\\bm{C} \\\\\n       &= \\begin{pmatrix}\n                1 & 0 & 0 & 0 \\\\\n                0 & 1 & 0 & 0 \\\\\n                0 & 0 & 1 & 0\\\\\n                0 & 0 & 0 & 1\n                \\end{pmatrix} -\n                \\begin{pmatrix} \\phantom{-}1 \\\\ -1 \\\\ -1 \\\\ -1 \\end{pmatrix} \\frac{1}{4} \\begin{pmatrix} 1 & -1 & -1 & -1 \\end{pmatrix} \\\\\n&= \\begin{pmatrix}\n                1 & 0 & 0 & 0 \\\\\n                0 & 1 & 0 & 0 \\\\\n                0 & 0 & 1 & 0\\\\\n                0 & 0 & 0 & 1\n                \\end{pmatrix} -\n                \\begin{pmatrix}\n                \\phantom{-}1 & -1 & -1 & -1 \\\\\n                -1 & \\phantom{-}1 & \\phantom{-}1 & \\phantom{-}1 \\\\\n                -1 & \\phantom{-}1 & \\phantom{-}1 & \\phantom{-}1 \\\\\n                -1 & \\phantom{-}1 & \\phantom{-}1 & \\phantom{-}1\n                \\end{pmatrix} \\\\\n                & =\n                \\begin{pmatrix}\n                \\frac{3}{4} & \\phantom{-}\\frac14 & \\phantom{-}\\frac14 & \\phantom{-}\\frac14 \\\\[0.1cm]\n                \\frac{1}{4} & \\phantom{-}\\frac34 & -\\frac14 & -\\frac14 \\\\[0.1cm]\n                \\frac{1}{4} & -\\frac14 & \\phantom{-}\\frac34 & -\\frac14  \\\\[0.1cm]\n                \\frac{1}{4} & -\\frac14 & -\\frac14 & \\phantom{-}\\frac34\n                \\end{pmatrix}\n\\end{align*}\n\\end{textblock}\n\n# Example: reconciling GDP forecasts\n\n## Example: reconciling GDP forecasts\n\n\\only<1>{\\full{IncomeApproach}}\n\\only<2>{\\full{ExpenditureApproach}}\n\\only<3>{\\full{GFCF}}\n\\only<4>{\\full{HFCE}}\n\n## Example: reconciling GDP forecasts\n\n* No unique hierarchy.\n* Several disaggregations with the same parent node\n* Not possible to represent using structural $\\bm{S}$ notation.\n* Instead, we can use the constraint $\\bm{C}$ notation.\n\n## Example: reconciling GDP forecasts\n\n\\alert{Using structural notation:}\n$$\n\\bm{y}^I_t = \\begin{bmatrix}x_t \\\\\\bm{a}^I_t \\\\ \\bm{b}^I_t\\end{bmatrix} = \\bm{S}^I\\bm{b}_t^I\\qquad\n\\bm{y}^E_t = \\begin{bmatrix}x_t \\\\\\bm{a}^E_t \\\\ \\bm{b}^E_t\\end{bmatrix} = \\bm{S}^E\\bm{b}_t^E\n$$\nwhere\n$$\\bm{S}^I = \\begin{bmatrix}\\bm{1}_{10}' \\\\\\bm{A}^I\\\\\\bm{I}_{10}\\end{bmatrix}\\qquad\n\\bm{S}^E = \\begin{bmatrix}\\bm{1}_{53}' \\\\\\bm{A}^E\\\\\\bm{I}_{53}\\end{bmatrix}$$\n\n* Can reconcile both trees, but the totals won't be equal.\n\n## Example: reconciling GDP forecasts\n\n\\alert{Using constraint notation:}\n$$\n  \\bm{C}\\bm{y}_t = \\bm{0}\n$$\nwhere\n$$ \\bm{y}_t = \\begin{bmatrix}x_t\\\\\n \\bm{a}^I_t\\\\\n \\bm{b}^I_t\\\\\n \\bm{a}^E_t\\\\\n \\bm{b}^E_t\n \\end{bmatrix}\n \\qquad\\text{and}\\qquad\n  \\bm{C} = \\begin{bmatrix}\n  1 & \\bm{0}_5' & -\\bm{1}_{10}' & \\bm{0}_{26}' & \\bm{0}_{53}' \\\\\n  1 & \\bm{0}_5' & \\bm{0}_{10}' & \\bm{0}_{26}' & -\\bm{1}_{53}' \\\\\n  \\bm{0}_5 & \\bm{I}_5 & - \\bm{A}^I & \\bm{0}_{5\\times 26} & \\bm{0}_{5\\times 53} \\\\\n  \\bm{0}_{26} & \\bm{0}_{26\\times 5} & \\bm{0}_{26\\times10} & \\bm{I}_{26} & -\\bm{A}^E\n  \\end{bmatrix}\n$$\\vspace{-0.2cm}\n\nRef: @Bisaglia2020\n\n# The geometry of forecast reconciliation\n\n## The coherent subspace\n\n\\begin{textblock}{9}(.2,1)\\fontsize{13}{13}\\sf\n\\begin{block}{Coherent subspace}\n$n_b$-dimensional linear subspace $\\mathfrak{s}\\subset \\mathbb{\\chi}^n$ for which linear constraints hold for all $\\bm{y}\\in\\mathfrak{s}$.\n\\end{block}\\vspace*{-0.3cm}\n\\begin{block}{Hierarchical time series}\nAn $n$-dimensional multivariate time series such that $\\bm{y}_t\\in\\mathfrak{s}\\quad\\forall t$.\n\\end{block}\\vspace*{-0.3cm}\n\\begin{block}{Coherent point forecasts}\n$\\tilde{\\bm{y}}_{t+h|t}$ is \\emph{coherent} if $\\tilde{\\bm{y}}_{t+h|t} \\in \\mathfrak{s}$.\n\\end{block}\\vspace*{-0.2cm}\n\\end{textblock}\n\\only<2-3>{\\begin{textblock}{7.5}(.2,6.75)\\fontsize{13}{13}\\sf\n\\begin{alertblock}{Base forecasts}\nLet $\\hat{\\bm{y}}_{t+h|t}$ be vector of \\emph{incoherent} initial $h$-step forecasts.$\\phantom{y_{t|h}}$\n\\end{alertblock}\n\\end{textblock}}\n\\only<3>{\\begin{textblock}{7.5}(8.3,6.75)\\fontsize{13}{13}\\sf\n\\begin{alertblock}{Reconciled forecasts}\nLet $\\psi$ be a mapping, $\\psi:\\mathbb{\\chi}^n\\rightarrow\\mathfrak{s}$.  $\\tilde{\\bm{y}}_{t+h|t}=\\psi(\\hat{\\bm{y}}_{t+h|t})$ ``reconciles'' $\\hat{\\bm{y}}_{t+h|t}$.\n\\end{alertblock}\n\\end{textblock}}\n\n\\placefig{9.4}{.0}{width=6.6cm}{3D_hierarchy}\n\\begin{textblock}{3}(11.4,5.6)\\fontsize{13}{13}\\sf\n\\begin{block}{}\n\\centerline{$ y_{Tot} = y_A + y_B$}\n\\end{block}\n\\end{textblock}\n\n## The coherent subspace\n\n\\begin{textblock}{5.7}(11.4,0.1)\n\\begin{minipage}{4cm}\n\\begin{block}{}\\centering\n\\begin{tikzpicture}\n\\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]\n\\tikzstyle[level distance=.3cm]\n\\tikzstyle[sibling distance=12cm]\n\\tikzstyle{level 1}=[sibling distance=10mm,font=\\small,set style={{every node}+=[fill=blue!15]}]\n\\node{Total}[edge from parent fork down]\n child {node {A}\n }\n child {node {B}\n }\n child {node {C}\n };\n\\end{tikzpicture}\n\\end{block}\n\\end{minipage}\n\\end{textblock}\n\nThe columns of $\\bm{S}$ form a basis set for $\\mathfrak{s}$.\n\nThey are not unique.\\newline Each corresponds to different vector of \"bottom-level\" series.\n\n\\only<2>{\\begin{block}{}\n\\centerline{$\\displaystyle\n\\bm{y} = \\begin{pmatrix}\\text{Total}\\\\A\\\\B\\\\C\\end{pmatrix}\\qquad\n\\bS  = \\begin{pmatrix*}[r]\n                \\phantom{-}1 & \\phantom{-}1 & \\phantom{-}1 \\\\\n                1 & 0 & 0 \\\\\n                0 & 1 & 0\\\\\n                0 & 0 & 1\n                \\end{pmatrix*} \\qquad\n  \\bm{b} = \\begin{pmatrix}\\phantom{Total}\\\\[-0.7cm]\n                A \\\\\n                B \\\\\n                C \\\\\n                \\end{pmatrix}\n$}\n\\end{block}}\n\\only<3>{\\begin{block}{}\n\\centerline{$\\displaystyle\n\\bm{y} = \\begin{pmatrix}\\text{Total}\\\\A\\\\B\\\\C\\end{pmatrix}\\qquad\n\\bS  =\n\\begin{pmatrix*}[r]\n                \\phantom{-}1 & 0 & 0 \\\\\n                0 & 0 & 1 \\\\\n                0 & 1 & 0\\\\\n                1 & -1 & -1\n                \\end{pmatrix*}\\qquad\n  \\bm{b} = \\begin{pmatrix}\n      \\text{Total} \\\\\n      B \\\\\n      A\n  \\end{pmatrix}\n$}\n\\end{block}}\n\\only<4>{\\begin{block}{}\n\\centerline{$\\displaystyle\n\\bm{y} = \\begin{pmatrix}\\text{Total}\\\\A\\\\B\\\\C\\end{pmatrix}\\qquad\n\\bS  =\n\\begin{pmatrix*}[r]\n                1 & 0 & 0 \\\\\n                1 & 0 & -1 \\\\\n                -1 & 1 & 1\\\\\n                1 & -1 & 0\n                \\end{pmatrix*}\\qquad\n  \\bm{b} = \\begin{pmatrix}\n      \\text{Total} \\\\\n      B+A \\\\\n      C+B\n  \\end{pmatrix}\n$}\n\\end{block}}\n\n\\vspace*{10cm}\n\n## Projections in linear algebra\n\n\\begin{textblock}{9}(.2,1.25)\n\\begin{tikzpicture}\n  % Define coordinates\n  \\coordinate (O) at (0,0);\n  \\coordinate (A) at (4,2);\n  \\coordinate (B) at (2,3);\n  \\coordinate (L) at (1,5);\n\n  % Draw axes\n  \\draw[->,thick] (0,0) -- (5,0) node[anchor=north] {$x$};\n  \\draw[->,thick] (0,0) -- (0,4) node[anchor=east] {$y$};\n\n  % Draw light\n  \\path [fill = yellow!30!white] (L) circle (.9cm);\n  \\path [fill = yellow!60!white] (L) circle (.6cm);\n  \\path [fill = yellow!90!white] (L) circle (.3cm);\n\n  % Draw vectors\n  \\draw[->,thick,red] (O) -- (A);\n  \\draw[->,thick,blue] (O) -- (B);\n\n  % Draw projection\n  \\coordinate (P) at ($(A)!(B)!(O)$);\n  \\only<2->{\\draw[->,thick,blue,dashed] (B) -- (P);}\n  \\only<2->{\\draw[->,thick,blue, dashed] (O) -- (P);}\n\\end{tikzpicture}\n\\end{textblock}\n\n\n\n\n\n\\begin{textblock}{10}(7,1.6)\n\\only<3>{\\includegraphics[width=8.8cm]{scatterplot1}}\n\\only<4>{\\includegraphics[width=8.8cm]{scatterplot2}}\n\\only<5>{\\includegraphics[width=8.8cm]{scatterplot3}}\n\\only<6>{\\includegraphics[width=8.8cm]{scatterplot4}}\n\\end{textblock}\n\n## Projections in linear algebra\n\n* A projection is a linear transformation $\\bm{M}$ such that $\\bm{M}^2=\\bm{M}$.\n* i.e., $M$ is idempotent: it leaves its image unchanged.\n* $\\bm{M}$ projects onto $\\mathfrak{s}$ if $\\bm{M}\\bm{y}=\\bm{y}$ for all $\\bm{y}\\in\\mathfrak{s}$.\n* All eigenvalues of $\\bm{M}$ are either 0 or 1.\n* All singular values of $\\bm{M}$ are greater than or equal to 1 (with equality iff $\\bm{M}$ is orthogonal).\n* A projection is *orthogonal* if $\\bm{M}'=\\bm{M}$.\n* If a projection is not orthogonal, it is called *oblique*.\n* In regression, OLS is an orthogonal projection onto space spanned by predictors.\n\n## Linear projection reconciliation\n\n\\only<1>{\\placefig{9.5}{1.5}{width=6.2cm}{InsampDir_2_George}}\n\\only<2>{\\placefig{9.5}{1.5}{width=6.2cm}{OrthProj_George}}\n\\only<3->{\\placefig{9.5}{1.5}{width=6.2cm}{ObliqProj_George}}\n\n\\begin{textblock}{9}(.5,1.5)\n  \\begin{itemize}\\tightlist\n  \\item $R$ is the most likely direction of deviations from $\\mathfrak{s}$.\n  \\only<1->{\\item Grey: potential base forecasts}\n  \\only<2->{\\item Red: reconciled forecasts}\n  \\only<2->{\\item Orthogonal projections (i.e., OLS) lead to smallest possible adjustments of base forecasts.}\n  \\only<3->{\\item Oblique projections (i.e., MinT) give reconciled forecasts with smallest variance.}\n  \\end{itemize}\n\\end{textblock}\n\n\\only<2->{\n  \\begin{textblock}{4.5}(11.2,7.6)\\fontsize{13}{14}\\sf\n  \\begin{block}{}\n  \\only<2>{Orthogonal projection}\n  \\only<3>{Oblique projection}\n  \\end{block}\n  \\end{textblock}\n}\n\n## Linear projection reconciliation\n\\fontsize{14}{16}\\sf\n\\vspace*{0.2cm}\\begin{alertblock}{}\n\\centerline{$\\tilde{\\bm{y}}_{t+h|t}= \\psi(\\hat{\\bm{y}}_{t+h|t}) = \\bm{M}\\hat{\\bm{y}}_{t+h|t}$}\n\\end{alertblock}\\vspace*{-0.5cm}\n\n* $\\bm{M}$ is a projection onto $\\mathfrak{s}$ if and only if $\\bm{M}\\bm{y}=\\bm{y}$ for all $\\bm{y}\\in\\mathfrak{s}$.\n* Coherent base forecasts are unchanged since $\\bm{M}\\hat{\\bm{y}}=\\hat{\\bm{y}}$\n* If $\\hat{\\bm{y}}$ is unbiased, then $\\tilde{\\bm{y}}$ is also unbiased since\n$$\n  \\E(\\tilde{\\bm{y}}_{t+h|t}) = \\E(\\bm{M}\\hat{\\bm{y}}_{t+h|t}) = \\bm{M} \\E(\\hat{\\bm{y}}_{t+h|t}) = \\E(\\hat{\\bm{y}}_{t+h|t}),\n$$\nand unbiased estimates must lie on $\\mathfrak{s}$.\n* The projection is orthogonal if and only if $\\bm{M}'=\\bm{M}$.\n* If $\\bm{S}$ forms a basis set for $\\mathfrak{s}$, then projections are of the form $\\bm{M} = \\bS(\\bS'\\bm{\\Psi}\\bS)^{-1}\\bS'\\bm{\\Psi}$ where $\\bm{\\Psi}$ is a positive definite matrix.\n\n\\vspace*{10cm}\n\n## Linear projection reconciliation\n\n\\vspace*{0.2cm}\\begin{alertblock}{}\n\\centerline{$\\tilde{\\bm{y}}_{t+h|t}= \\psi(\\hat{\\bm{y}}_{t+h|t}) = \\bm{M}\\hat{\\bm{y}}_{t+h|t},\\qquad\\text{where}\\quad \\bm{M} = \\bS(\\bS'\\bm{\\Psi}\\bS)^{-1}\\bS'\\bm{\\Psi}$}\n\\end{alertblock}\\vspace*{.01cm}\n\\begin{block}{}\\vspace*{-0.6cm}\n\\begin{align*}\n&\\text{OLS:}  && \\bm{\\Psi}=\\bm{I} &&& \\bm{M} & = \\bm{S}(\\bm{S}'\\bm{S})^{-1}\\bm{S}' && = \\bm{I} - \\bm{C}'(\\bm{C}\\bm{C}')^{-1}\\bm{C} \\\\\n&\\text{MinT:} && \\bm{\\Psi}=\\bm{W}_h &&&\\bm{M} & = \\bS(\\bS'\\bm{W}_h^{-1}\\bS)^{-1}\\bS'\\bm{W}_h^{-1} && = \\bm{I} - \\bm{W}_h\\bm{C}'(\\bm{C}\\bm{W}_h\\bm{C}')^{-1}\\bm{C}\n\\end{align*}\n\\end{block}\\vspace*{-0.3cm}\n\n* $\\bm{M}$ is orthogonal iff $\\bm{\\Psi}=\\bm{I}$.\n* $\\bm{W}_h = \\var[\\by_{T+h} - \\hat{\\by}_{T+h|T} \\mid \\by_1,\\dots,\\by_T]$ is the covariance matrix of the base forecast errors.\n* $\\bm{V}_h = \\var[\\by_{T+h} - \\tilde{\\by}_{T+h|T}  \\mid \\by_1,\\dots,\\by_T]  = \\bm{M}\\bm{W}_h\\bm{M}'$ is minimized when  $\\bm{\\Psi} = \\bm{W}_h$.\n\n\\vspace*{10cm}\n\n## Mean square error bounds\n\n\\begin{textblock}{6.4}(9,-0.1)\\begin{block}{}\n\\citet{htsgeometry}\n\\end{block}\\end{textblock}\n\n\\vspace*{0.2cm}\\begin{alertblock}{Distance reducing property}\nLet $\\|\\bm{u}\\|_{\\bm{\\Psi}} = \\bm{u}'\\bm{\\Psi}\\bm{u}$. Then\n  \\centerline{$\\|\\bm{y}_{t+h}-\\tilde{\\bm{y}}_{t+h|t}\\|_{\\bm{\\Psi}}\\le\\|\\bm{y}_{t+h}-\\hat{\\bm{y}}_{t+h|t}\\|_{\\bm{\\Psi}}$}\n\\end{alertblock}\n\n * $\\bm{\\Psi}$-projection is guaranteed to improve forecast accuracy over base forecasts *using this distance measure*.\n * Distance reduction holds for any realisation and any forecast.\n * OLS reconciliation minimizes Euclidean distance.\n * Other measures of forecast accuracy may be worse.\n\n## Mean square error bounds\n\n\\begin{textblock}{6.4}(9,-0.1)\\begin{block}{}\n\\citet{wickramasuriya2021properties}\n\\end{block}\\end{textblock}\n\n\\begin{block}{}\\vspace*{-0.6cm}\n\\begin{align*}\n\\|\\bm{y}_{t+h} - \\tilde{\\bm{y}}_{t+h}\\|_2^2\n &= \\|\\bm{M}(\\bm{y}_{t+h} - \\hat{\\bm{y}}_{t+h})\\|_2^2 \\\\\n &\\le \\|\\bm{M}\\|_2^2 \\|\\bm{y}_{t+h} - \\hat{\\bm{y}}_{t+h}\\|_2^2 \\\\\n & = \\sigma_{\\text{max}}^2\\|\\bm{y}_{t+h} - \\hat{\\bm{y}}_{t+h}\\|_2^2\n\\end{align*}\n\\end{block}\n\n * $\\sigma_{\\text{max}}$ is the largest eigenvalue of $\\bm{M}$\n * $\\sigma_{\\text{max}}\\ge1$ as $\\bm{M}$ is a projection matrix.\n * Every projection reconciliation is better than base forecasts using Euclidean distance.\n\n## Mean square error bounds\n\n\\begin{textblock}{6.4}(9,-0.1)\\begin{block}{}\n\\citet{wickramasuriya2021properties}\n\\end{block}\\end{textblock}\n\\vspace*{0.2cm}\\begin{block}{}\\vspace*{-0.6cm}\n\\begin{align*}\n    & \\text{tr}\\Big(\\E[\\bm{y}_{t+h} - \\tilde{\\bm{y}}^{\\text{MinT}}_{t+h|t}]'[\\bm{y}_{t+h} - \\tilde{\\bm{y}}^{\\text{MinT}}_{t+h|t}]\\Big) \\\\\n\\le~ & \\text{tr}\\Big(\\E[\\bm{y}_{t+h} - \\tilde{\\bm{y}}^{\\text{OLS}}_{t+h|t}]'[\\bm{y}_{t+h} - \\tilde{\\bm{y}}^{\\text{OLS}}_{t+h|t}]\\Big) \\\\\n\\le~ & \\text{tr}\\Big(\\E[\\bm{y}_{t+h} - \\hat{\\bm{y}}_{t+h|t}]'[\\bm{y}_{t+h} - \\hat{\\bm{y}}_{t+h|t}]\\Big)\n\\end{align*}\n\\end{block}\n\nUsing sums of variances:\n\n* MinT reconciliation is better than OLS reconciliation\n* OLS reconciliation is better than base forecasts\n\n# Optimization and reconcilation\n\n## Minimum trace reconciliation\n\n\\vspace*{0.2cm}\\begin{alertblock}{Minimum trace (MinT) reconciliation}\nIf $\\bS\\bG$ is a projection, then the trace of $\\bm{V}_h = \\text{Var}(\\tilde{\\bm{y}}_{t+h|t} - \\bm{y}_{t+h})$ is \\textbf{minimized} when\n\\centerline{$\\bG = (\\bS'\\bm{W}_h^{-1}\\bS)^{-1}\\bS'\\bm{W}_h^{-1}$}\n\\end{alertblock}\n\\begin{block}{}\n\\centerline{$\\displaystyle\\textcolor{red}{\\tilde{\\by}_{T+h|T}}\n=\\bS(\\bS'\\bm{W}_h^{-1}\\bS)^{-1}\\bS'\\bm{W}_h^{-1}\\textcolor{blue}{\\hat{\\by}_{T+h|T}}$}\n\\end{block}\n\\centerline{\\hspace*{1cm}\\textcolor{red}{Reconciled forecasts}\\hfill\\textcolor{blue}{Base forecasts}\\hspace*{2cm}}\n\n* Trace of $\\bm{V}_h$ is sum of forecast variances.\n* MinT solution is $L_2$ **optimal** amongst linear unbiased forecasts.\n\n## A game theoretic perspective\n\\fontsize{14}{16}\\sf\n\n\\begin{textblock}{6.4}(9,-0.1)\\begin{block}{}\n\\citet{Van_ErvCug2015}\n\\end{block}\\end{textblock}\n\nFind the solution to the minimax problem\n$$\nV = \\mathop{min}_{\\tilde{\\bm{y}} \\in \\mathfrak{s}}\n\\mathop{max}_{\\bm{y}\\in \\mathfrak{s}}\n\\left\\{\\ell(\\bm{y},\\tilde{\\bm{y}}) -\n\\ell(\\bm{y},\\hat{\\bm{y}})\n\\right\\},\n$$\nwhere $\\ell$ is a loss function, and $\\mathfrak{s}$ is the coherent subspace.\n\n* $V\\le0$: reconciliation guaranteed to reduce loss.\n* If $\\ell(\\bm{y},\\tilde{\\bm{y}}) = \\|\\bm{y}- \\tilde{\\bm{y}}\\|_{\\bm{\\Psi}} = (\\bm{y}-\\tilde{\\bm{y}})'\\bm{\\Psi}(\\bm{y}-\\tilde{\\bm{y}})$, where $\\bm{\\Psi}$ is any symmetric pd matrix, then:\n\n  1. $\\tilde{\\bm{y}}=\\bm{S}(\\bm{S}'\\bm{\\Psi}\\bm{S})^{-1}\\bm{S}'\\bm{\\Psi}\\hat{\\bm{y}}$ will always improve upon the base forecasts;\n  2. The MinT solution $\\tilde{\\bm{y}}=\\bm{S}(\\bm{S}'\\bm{W}_h^{-1}\\bm{S})^{-1}\\bm{S}'\\bm{W}_h^{-1}\\hat{\\bm{y}}$ will optimise loss in expectation over any choice of $\\bm{\\Psi}$.\n\n## Biased reconciliation\n\n\\begin{textblock}{6.4}(9,-0.1)\\begin{block}{}\n\\citet{Ben_TaiEtAl2019}\n\\end{block}\\end{textblock}\n\nRegularized empirical risk minimization problem:\n$$\\min_{\\bm{G}} \\frac{1}{Nn}\\|\\bm{Y} - \\hat{\\bm{Y}}\\bm{G}'\\bm{S}'\\|_F + \\lambda \\|\\text{vec}{\\bm{G}}\\|_1,\n$$\n\n* $N=T-T_1-h+1$,\\quad $T_1$ is minimum training sample size\n* $\\|\\cdot\\|_F$ is the Frobenius norm\n* $\\bm{Y} = [\\bm{y}_{T_1+h}, \\dots, \\bm{y}_{T}]'$\n* $\\hat{\\bm{Y}} = [\\hat{\\bm{y}}_{T_1+h|T_1}, \\dots, \\hat{\\bm{y}}_{T|T-h}]'$\n* $\\lambda$ is a regularization parameter\n\nWhen $\\lambda=0$:\\qquad  $\\hat{\\bm{G}} = \\bm{B}'\\hat{\\bm{Y}}(\\hat{\\bm{Y}}'\\hat{\\bm{Y}})^{-1}$\nwhere $\\bm{B} = [\\bm{b}_{T_1+h}, \\dots, \\bm{b}_{T}]'$.\n\nReference: @Ben_TaiEtAl2019\n\n## MinT expressed as a regression\n\nSince $\\tilde{\\bm{b}}_{t+h|t} = (\\bm{S}'\\bm{W}_h^{-1}\\bm{S})^{-1}\\bm{S}'\\bm{W}_h^{-1}\\hat{\\bm{y}}_{t+h|t}$, we can write the MinT solution as a regression problem:\n\\begin{block}{}\\vspace*{-0.7cm}\n\\begin{align*}\n\\tilde{\\bm{b}}_{t+h|t} &= \\text{arg min}_{\\bm{b}}\\big[\\hat{\\bm{y}}_{t+h|t} - \\bm{S}\\bm{b}\\big]' \\bm{W}_h^{-1}\\big[\\hat{\\bm{y}}_{t+h|t} - \\bm{S}\\bm{b}\\big] \\\\\n& =\\text{arg min}_{\\bm{b}}\\big[\\bm{b}'\\bm{S}'\\bm{W}_h^{-1}\\bm{S}\\bm{b} - 2\\bm{b}'\\bm{S}'\\bm{W}_h^{-1}\\hat{\\bm{y}}_{t+h|t} +\n\\hat{\\bm{y}}_{t+h|t}'\\bm{W}_h^{-1}\\hat{\\bm{y}}_{t+h|t} \\big]\\\\\n& =\\text{arg min}_{\\bm{b}}\\big[\\bm{b}'\\bm{S}'\\bm{W}_h^{-1}\\bm{S}\\bm{b} - 2\\bm{b}'\\bm{S}'\\bm{W}_h^{-1}\\hat{\\bm{y}}_{t+h|t}\\big]\n\\end{align*}\n\\end{block}\\vspace*{-0.2cm}\n\n* MinT solution is equivalent to a GLS regression of $\\hat{\\bm{y}}_{t+h|t}$ on $\\bm{S}$ with covariance weights $\\bm{W}_h^{-1}$.\n* The estimated coefficients are the forecasts of the bottom level series.\n\n\\vspace*{10cm}\n\n## Non-negative forecasts\n\\fontsize{14}{15}\\sf\n\\vspace*{0.1cm}\\begin{alertblock}{}\n\\centerline{$\\min_{\\bm{G}_h}\\text{tr}\\Big(\\E[\\bm{y}_{t+h} - \\bm{S}\\bm{G}_h\\hat{\\bm{y}}_{t+h|t}]'[\\bm{y}_{t+h} - \\bm{S}\\bm{G}_h\\hat{\\bm{y}}_{t+h|t}]\\Big)$}\n\\centerline{such that $\\bm{b}_{t+h|t} = \\bm{G}_h\\hat{\\bm{y}}_{t+h|t} \\ge 0$}\n\\end{alertblock}\\pause\\vspace*{-0.2cm}\n\n\\begin{block}{Solve via quadratic programming:}\n$$\n  \\text{min}_{\\bm{b}} \\big[\\bm{b}'\\bS'\\bm{W}_h^{-1}\\bS\\bm{b} - 2 \\bm{b}'\\bS'\\bm{W}_h^{-1}\\hat{\\bm{y}}_{T+h|T}\\big] \\quad \\text{s.t.~~} \\bm{b} \\ge 0\n$$\n\\rightline{\\citep{nonnegmint}}\n\\end{block}\\pause\\vspace*{-0.1cm}\n\n### Set-negative-to-zero heuristic solution\n  * Negative reconciled forecasts at bottom level set to zero\n  * Remaining forecasts computed via aggregation\n\n\\rightline{\\citep{di2023spatio}}\n\n## Immutable forecasts\n\n\\begin{textblock}{6.4}(9,-0.1)\\begin{block}{}\n\\citet{ZhaEtAl2022}\n\\end{block}\\end{textblock}\n$\\displaystyle \\hat{\\bm{y}}_{t+h|t} = \\begin{bmatrix}\\hat{\\bm{a}}_{t+h|t} \\\\ \\hat{\\bm{v}}_{t+h|t} \\\\ \\hat{\\bm{u}}_{t+h|t}\\end{bmatrix} = \\begin{bmatrix} \\bm{A}_1 & \\bm{A}_2 \\\\ \\bm{I}_{n_b-k} & \\bm{O} \\\\ \\bm{O} & \\bm{I}_k \\end{bmatrix} \\begin{bmatrix}\\hat{\\bm{v}}_{t+h|t} \\\\ \\hat{\\bm{u}}_{t+h|t}\\end{bmatrix}$\\vspace*{-0.5cm}\n\nSuppose $\\hat{\\bm{u}}_{t+h|t}$ are fixed and let $\\hat{\\bm{w}}_{t+h|t} = \\begin{bmatrix}\\hat{\\bm{a}}_{t+h|t} - \\bm{A}_2 \\hat{\\bm{u}}_{t+h|t} \\\\ \\hat{\\bm{v}}_{t+h|t}\\end{bmatrix}$.\n\\begin{block}{Optimization problem}\n\\centerline{$\\displaystyle\\text{min}_{\\bm{v}}\\big[\\hat{\\bm{w}}_{t+h|t} - \\bm{A}_3\\bm{v}\\big]' \\bm{W}_{\\bm{v}}^{-1}\\big[\\hat{\\bm{w}}_{t+h|t} - \\bm{A}_3\\bm{v}\\big]\\qquad\\text{where}\\qquad\n\\bm{A}_3 = \\begin{bmatrix}\\bm{A}_1 \\\\\\bm{I}_{n_b-k}\\end{bmatrix}$}\nand $\\bm{W}_{\\bm{v}}$ contains elements of $\\bm{W}_h$ corresponding to $\\hat{\\bm{v}}_{t+h|t}$.\n\\end{block}\n\\vspace*{10cm}\n\n## Immutable forecasts\n\n\\begin{textblock}{6.4}(9,-0.1)\\begin{block}{}\n\\citet{ZhaEtAl2022}\n\\end{block}\\end{textblock}\n$\\displaystyle \\hat{\\bm{y}}_{t+h|t} = \\begin{bmatrix}\\hat{\\bm{a}}_{t+h|t} \\\\ \\hat{\\bm{v}}_{t+h|t} \\\\ \\hat{\\bm{u}}_{t+h|t}\\end{bmatrix} = \\begin{bmatrix} \\bm{A}_1 & \\bm{A}_2 \\\\ \\bm{I}_{n_b-k} & \\bm{O} \\\\ \\bm{O} & \\bm{I}_k \\end{bmatrix} \\begin{bmatrix}\\hat{\\bm{v}}_{t+h|t} \\\\ \\hat{\\bm{u}}_{t+h|t}\\end{bmatrix}$\\vspace*{-0.5cm}\n\nSuppose $\\hat{\\bm{u}}_{t+h|t}$ are fixed and let $\\hat{\\bm{w}}_{t+h|t} = \\begin{bmatrix}\\hat{\\bm{a}}_{t+h|t} - \\bm{A}_2 \\hat{\\bm{u}}_{t+h|t} \\\\ \\hat{\\bm{v}}_{t+h|t}\\end{bmatrix}$.\n\\begin{block}{Solve with non-negativity constraint}\n\\centerline{$\\displaystyle\\text{min}_{\\bm{v}}\\big[\\hat{\\bm{w}}_{t+h|t} - \\bm{A}_3\\bm{v}\\big]' \\bm{W}_{\\bm{v}}^{-1}\\big[\\hat{\\bm{w}}_{t+h|t} - \\bm{A}_3\\bm{v}\\big]\\qquad\\text{where}\\qquad\n\\bm{A}_3 = \\begin{bmatrix}\\bm{A}_1 \\\\\\bm{I}_{n_b-k}\\end{bmatrix}$}\n$$\\text{such that}\\qquad \\bm{A}_3 \\bm{v} \\ge \\begin{bmatrix}-\\bm{A}_2\\hat{\\bm{u}}_{t+h|t}\\\\ \\bm{0}\\end{bmatrix}$$\n\\end{block}\n\n## Reconciliation and regularization\n\n@Mishchenko2019:\\newline Optimize all forecasts with an incoherence penalty\n$$\n\\text{min}_{\\hat{\\bm{y}}_{t}} \\sum_{t=1}^T \\|\\bm{y}_t - \\hat{\\bm{y}}_t\\|_2 + \\lambda \\sum_{t=1}^T \\|\\hat{\\bm{y}}_t - \\bm{S}_t \\hat{\\bm{b}}_t\\|_2\n$$\\pause\n\n\n@Shiratori2020:\\newline Optimize bottom level forecasts with an incoherence penalty\n$$\n\\text{min}_{\\hat{\\bm{b}}_{t}} \\sum_{t=1}^T \\|\\hat{\\bm{b}}_t - \\bm{b}_t\\|_2 + \\sum_{t=1}^T \\bm{\\Lambda} \\|\\bm{a}_t - \\bm{A}_t \\hat{\\bm{b}}_t\\|_2\n$$\n\n# In-built coherence\n\n## In-built coherence\n\n**Two-step approach**: compute base forecasts $\\hat{\\bm{y}}_h$, and then reconcile them to produce $\\tilde{\\bm{y}}_h$.\n\n**One-step approaches:** compute coherent $\\tilde{\\bm{y}}_h$ directly.\n\n  * @lhf: linear regression models\n  * @PenvanDal2017: state space models\n  * @villegas2018supply: state space models\n\n## In-built coherence using linear models\n\\fontsize{13}{14}\\sf\nSuppose $\\hat{y}_{t,i} = \\hat{\\bm{\\beta}}_{i}' \\bm{x}_{t,i}$\nwith $\\bm{x}_{t,i}= (1, x_{t,1,i},\\dots,x_{t,p,i})$&nbsp; & &nbsp;\\rlap{$\\hat{\\bm{y}}_i = (\\hat{y}_{1,i}, \\dots, \\hat{y}_{T,i})$.}\n\\pause\n\\begin{align*}\n\\textcolor{blue}{\\begin{pmatrix}\n  \\hat{\\bm{y}}_1\\\\\n  \\hat{\\bm{y}}_2\\\\\n  \\vdots\\\\\n  \\hat{\\bm{y}}_n\n  \\end{pmatrix}} &=\n  \\textcolor{red}{\\begin{pmatrix}\n  \\bm{X}_1 & 0        & \\dots  & 0\\\\\n  0        & \\bm{X}_2 & \\ddots & \\vdots \\\\\n  \\vdots   & \\ddots   & \\ddots & 0\\\\\n  0        & \\dots    & 0      & \\bm{X}_n\n  \\end{pmatrix}}\n  \\begin{pmatrix}\n  \\hat{\\bm{\\beta}}_1\\\\\n  \\hat{\\bm{\\beta}}_2\\\\\n  \\vdots\\\\\n  \\hat{\\bm{\\beta}}_n\n\\end{pmatrix},\n&&\\quad\n  \\bm{X}_i = \\begin{pmatrix}\n  1 & x_{1,i,1} & x_{1,i,2} & \\dots & x_{1,i,p}\\\\\n  1 & x_{2,i,1} & x_{2,i,2} & \\dots & x_{2,i,p}\\\\\n  \\vdots & \\vdots & \\vdots & & \\vdots \\\\\n  1 & x_{T,i,1} & x_{T,i,2} & \\dots & x_{T,i,p}\n\\end{pmatrix}\n\\end{align*}\\pause\n$\\hat{\\bm{B}} = (\\textcolor{red}{\\bm{X}}'\\textcolor{red}{\\bm{X}})^{-1} \\textcolor{red}{\\bm{X}}'\\textcolor{blue}{\\bm{Y}}$\n\\pause\\qquad\n$\\hat{\\bm{y}}_{t+h} = \\bm{X}_{t+h}^* \\hat{\\bm{B}}$\n\\pause\\qquad\n$\\bm{X}^*_{t+h} =\\text{diag}(\\bm{x}_{t+h,i}', \\dots, \\bm{x}_{t+h,n}')$\n\\pause\n\\begin{alertblock}{}\\vspace*{-0.8cm}\n\\begin{align*}\n\\tilde{\\bm{y}}_{t+h} & = \\bm{S}(\\bm{S}'\\bm{W}_h\\bm{S})^{-1}\\bm{S}'\\bm{W}_h\n                            \\hat{\\bm{y}}_{t+h}\n                         = \\bm{S}(\\bm{S}'\\bm{W}_h\\bm{S})^{-1}\\bm{S}'\\bm{W}_h\n                            \\bm{X}_{t+h}^* (\\textcolor{red}{\\bm{X}}'\\textcolor{red}{\\bm{X}})^{-1} \\textcolor{red}{\\bm{X}}'\\textcolor{blue}{\\bm{Y}}\n\\\\\n\\bm{V}_h &= \\sigma^2\\bm{S}(\\bm{S}'\\bm{W}_h\\bm{S})^{-1}\\bm{S}'\\bm{W}_h\\big[1 + \\bm{X}_{T+h}^*(\\textcolor{red}{\\bm{X}}'\\textcolor{red}{\\bm{X}})^{-1}(\\bm{X}_{T+h}^*)'\\big] \\bm{W}_h\\bm{S}'(\\bm{S}'\\bm{W}_h\\bm{S})^{-1}\\bm{S}'\n\\end{align*}\n\\end{alertblock}\n\\only<4->{\\begin{alertblock}{}\nReference: \\citet{lhf}\n\\end{alertblock}}\n\n\\vspace*{10cm}\n\n## In-built coherence using state space models\n\n@PenvanDal2017 propose the state space model\n\\begin{align*}\n\\bm{y}_t &= \\bm{S}\\bm{\\mu}_t + \\bm{Z}_t\\bm{\\beta} + \\bm{\\varepsilon}_t, && \\bm{\\varepsilon}_t \\sim N(\\bm{0}, \\bm{\\Sigma}_{\\bm{\\varepsilon}}),\\\\\n\\bm{\\mu}_t &= \\bm{\\mu}_{t-1} + \\bm{\\eta}_t, && \\bm{\\eta}_t \\sim N(\\bm{0}, \\bm{\\Sigma}_{\\bm{\\eta}}).\n\\end{align*}\n\n* Coherent forecasts arise naturally using the Kalman filter\n* Covariance matrices difficult to estimate except for small hierarchies.\n* Requires the same model for all series\n* A related approach proposed by @villegas2018supply\n\n# Time series cross-validation\n\n## Time series cross-validation\n\n\n::: {.cell hash='fr2_cache/beamer/tscvplots_d6d913293084e551ba68a6363951b0d6'}\n\n:::\n\n\n**Traditional evaluation**\n\n\n::: {.cell hash='fr2_cache/beamer/traintest1_74d7639d04a1c167f1a92be6fd34ebc8'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/traintest1-1.pdf)\n:::\n:::\n\n\n\\pause\n\n**Time series cross-validation**\n\n\n::: {.cell hash='fr2_cache/beamer/tscvggplot1_1f5c926b228ef77ba2e92c9dded64796'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/tscvggplot1-1.pdf)\n:::\n:::\n\n\n## Time series cross-validation {-}\n\n**Traditional evaluation**\n\n\n::: {.cell hash='fr2_cache/beamer/traintest2_847083695e1123760ab615d5d11af1e0'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/traintest2-1.pdf)\n:::\n:::\n\n\n**Time series cross-validation**\n\n\n::: {.cell hash='fr2_cache/beamer/tscvggplot2_f10609406f30cd1077511049e0f8f8c3'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/tscvggplot2-1.pdf)\n:::\n:::\n\n\n## Time series cross-validation {-}\n\n**Traditional evaluation**\n\n\n::: {.cell hash='fr2_cache/beamer/traintest3_43db39834d3a3b8375249d4b87863d10'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/traintest3-1.pdf)\n:::\n:::\n\n\n**Time series cross-validation**\n\n\n::: {.cell hash='fr2_cache/beamer/tscvggplot3_4a8eef36d966b3a62753bf04a4330f8b'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/tscvggplot3-1.pdf)\n:::\n:::\n\n\n## Time series cross-validation {-}\n\n**Traditional evaluation**\n\n\n::: {.cell hash='fr2_cache/beamer/traintest4_02d2d13cb500925815a37998dacd0527'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/traintest4-1.pdf)\n:::\n:::\n\n\n**Time series cross-validation**\n\n\n::: {.cell hash='fr2_cache/beamer/tscvggplot4_949fd05de46dafed9646ef1efff54595'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/tscvggplot4-1.pdf)\n:::\n:::\n\n\n\\only<2>{\\begin{textblock}{7.7}(.5,6.2)\\begin{block}{}\\fontsize{12}{13}\\sf\n\\begin{itemize}\\tightlist\n\\item Forecast accuracy averaged over test sets.\n\\item Also known as \"evaluation on a rolling forecasting origin\"\n\\end{itemize}\\end{block}\\end{textblock}}\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr2_cache/beamer/tourismdata0_3dd4402a28ceeb0055ccb3400ce550ac'}\n\n```{.r .cell-code}\ntourism\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 18,000 x 5 [1M]\n# Key:       state, zone, region [75]\n      month state zone      region visitors\n      <mth> <chr> <chr>     <chr>     <dbl>\n 1 1998 Jan NSW   Metro NSW Sydney     926.\n 2 1998 Feb NSW   Metro NSW Sydney     647.\n 3 1998 Mar NSW   Metro NSW Sydney     716.\n 4 1998 Apr NSW   Metro NSW Sydney     621.\n 5 1998 May NSW   Metro NSW Sydney     598.\n 6 1998 Jun NSW   Metro NSW Sydney     601.\n 7 1998 Jul NSW   Metro NSW Sydney     720.\n 8 1998 Aug NSW   Metro NSW Sydney     645.\n 9 1998 Sep NSW   Metro NSW Sydney     633.\n10 1998 Oct NSW   Metro NSW Sydney     771.\n# i 17,990 more rows\n```\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr2_cache/beamer/tourismdata_1b375874638f8f398bcb1f1db500c812'}\n\n```{.r .cell-code}\ntourism_agg <- tourism |>\n  aggregate_key(state/zone/region, visitors = sum(visitors))\ntourism_stretch <- tourism_agg |>\n  stretch_tsibble(.init = 48, .step = 1)\ntourism_stretch\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 3,057,120 x 6 [1M]\n# Key:       .id, state, zone, region [21,230]\n      month state  zone   region   visitors   .id\n      <mth> <chr*> <chr*> <chr*>      <dbl> <int>\n 1 1998 Jan NSW    ACT    Canberra     210.     1\n 2 1998 Feb NSW    ACT    Canberra     156.     1\n 3 1998 Mar NSW    ACT    Canberra     185.     1\n 4 1998 Apr NSW    ACT    Canberra     178.     1\n 5 1998 May NSW    ACT    Canberra     134.     1\n 6 1998 Jun NSW    ACT    Canberra     105.     1\n 7 1998 Jul NSW    ACT    Canberra     142.     1\n 8 1998 Aug NSW    ACT    Canberra     137.     1\n 9 1998 Sep NSW    ACT    Canberra     166.     1\n10 1998 Oct NSW    ACT    Canberra     150.     1\n# i 3,057,110 more rows\n```\n:::\n:::\n\n\n\n\n\n## Example: Australian tourism\n\\fontsize{8}{9}\\sf\n\n\n::: {.cell hash='fr2_cache/beamer/tourismmodels_f6130c54a13e938196c81a4634f15fd5'}\n\n```{.r .cell-code}\nfit <- tourism_stretch |>\n  model(ets = ETS(visitors))\nfit\n```\n:::\n\n\n```\n# A mable: 21,230 x 5\n# Key:     .id, state, zone, region [21,230]\n     .id state  zone            region                   ets\n   <int> <chr*> <chr*>          <chr*>               <model>\n 1     1 NSW    ACT             Canberra        <ETS(A,N,N)>\n 2     1 NSW    ACT             <aggregated>    <ETS(A,N,N)>\n 3     1 NSW    Metro NSW       Central Coast   <ETS(A,N,A)>\n 4     1 NSW    Metro NSW       Sydney          <ETS(A,N,N)>\n 5     1 NSW    Metro NSW       <aggregated>    <ETS(M,N,M)>\n 6     1 NSW    North Coast NSW Hunter          <ETS(A,N,N)>\n 7     1 NSW    North Coast NSW North Coast NSW <ETS(M,N,M)>\n 8     1 NSW    North Coast NSW <aggregated>    <ETS(M,N,M)>\n 9     1 NSW    North NSW       Blue Mountains  <ETS(M,N,N)>\n10     1 NSW    North NSW       Central NSW     <ETS(A,N,N)>\n# i 21,220 more rows\n# i Use `print(n = ...)` to see more rows\n```\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr2_cache/beamer/fctourism_e53c5232041becdb52c03dc4447abd83'}\n\n```{.r .cell-code}\nfc <- fit |>\n  reconcile(\n    ols = min_trace(ets, method = \"ols\"),\n    wlsv = min_trace(ets, method = \"wls_var\"),\n    wlss = min_trace(ets, method = \"wls_struct\"),\n    mint_s = min_trace(ets, method = \"mint_shrink\"),\n  ) |>\n  forecast(h = \"2 years\")\nfc\n```\n:::\n\n\n```\n# A fable: 2,547,600 x 9 [1M]\n# Key:     .id, state, zone, region, .model [106,150]\n     .id state  zone   region   .model    month     visitors .mean     h\n   <int> <chr*> <chr*> <chr*>   <chr>     <mth>       <dist> <dbl> <int>\n 1     1 NSW    ACT    Canberra ets    2002 Jan N(169, 1553)  169.     1\n 2     1 NSW    ACT    Canberra ets    2002 Feb N(169, 1553)  169.     2\n 3     1 NSW    ACT    Canberra ets    2002 Mar N(169, 1553)  169.     3\n 4     1 NSW    ACT    Canberra ets    2002 Apr N(169, 1553)  169.     4\n 5     1 NSW    ACT    Canberra ets    2002 May N(169, 1553)  169.     5\n 6     1 NSW    ACT    Canberra ets    2002 Jun N(169, 1553)  169.     6\n 7     1 NSW    ACT    Canberra ets    2002 Jul N(169, 1553)  169.     7\n 8     1 NSW    ACT    Canberra ets    2002 Aug N(169, 1553)  169.     8\n 9     1 NSW    ACT    Canberra ets    2002 Sep N(169, 1553)  169.     9\n10     1 NSW    ACT    Canberra ets    2002 Oct N(169, 1553)  169.    10\n# i 2,547,590 more rows\n# i Use `print(n = ...)` to see more rows\n```\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr2_cache/beamer/fcaccuracy2_11f335687a434f94eb1d3ed00b43eeb4'}\n::: {.cell-output-display}\n![](fr2_files/figure-beamer/fcaccuracy2-1.pdf)\n:::\n:::\n\n\n## Example: Australian tourism\n\n\n::: {.cell hash='fr2_cache/beamer/fcaccuracy3_4937b69be0392edf1a6aa359060d6d53'}\n\n:::\n\n\n\\fontsize{9}{9}\\sf\n\\begin{textblock}{7.15}(0.5,1.2)\n\\begin{alertblock}{\\fontsize{11}{11}\\sf\\centering Overall}\\centering\n\\input Overall.tex\n\\end{alertblock}\n\\end{textblock}\n\\begin{textblock}{7.15}(8.35,1.2)\n\\begin{block}{\\fontsize{11}{11}\\sf\\centering National}\\centering\n\\input National.tex\n\\end{block}\n\\end{textblock}\n\\begin{textblock}{4.5}(.5,5)\n\\begin{block}{\\fontsize{11}{11}\\sf\\centering State}\\centering\n\\input State.tex\n\\end{block}\n\\end{textblock}\n\\begin{textblock}{4.5}(5.75,5)\n\\begin{block}{\\fontsize{11}{11}\\sf\\centering Zone}\\centering\n\\input Zone.tex\n\\end{block}\n\\end{textblock}\n\\begin{textblock}{4.5}(11,5)\n\\begin{block}{\\fontsize{11}{11}\\sf\\centering Region}\\centering\n\\input Region.tex\n\\end{block}\n\\end{textblock}\n\n\n\n## ML reconciliation\n\n\\placefig{7}{0}{width=9.cm, height=20cm}{mlflow}\n\n\\begin{textblock}{7}(0,1.2)\\fontsize{11}{12}\\sf\n\\begin{enumerate}\\tightlist\n\\item Split all series using time series cross-validation\n\\item For each training set, compute one-step-ahead forecasts for all series\n\\item For each bottom-level series, use RF or XGB to predict values using forecasts of all series as inputs\n\\item Forecast all series\n\\item For each bottom-level series, apply ML model to improve forecasts\n\\item Aggregate bottom-level forecasts to obtain forecasts for other series.\n\\end{enumerate}\n\\end{textblock}\n\\begin{textblock}{6,5}(0.5,7.8)\\fontsize{11}{12}\\sf\n\\begin{block}{}\nSpiliotis et al. (ASC, 2021)\\nocite{hfrml}\n\\end{block}\n\\end{textblock}\n\n## ML reconciliation: tourism data\n\n\\fontsize{11}{11}\\sf\\hspace*{-0.8cm}\n\\begin{tabular}{l c c c c c}\n    \\textbf{Method} & \\textbf{Total} & \\textbf{States} & \\textbf{Zones} & \\textbf{Regions} & \\textbf{Average} \\\\\n    \\hline\n    \\multicolumn{6}{c}{MASE} \\\\\n    \\hline\n    MinT-Struct          & 1.094            & 0.968            & 0.887            & 0.843            & 0.948 \\\\\n    MinT-Shrink & 1.047 & \\textbf{0.956} & 0.872 & 0.824 & 0.925 \\\\\n    ML-RF           & 1.045            & 0.964            & 0.859            & 0.812            & 0.920 \\\\\n    ML-XGB          & \\textbf{1.043}   & 0.965            & \\textbf{0.859}   & \\textbf{0.812}   & \\textbf{0.920} \\\\\n    \\hline\n    \\multicolumn{6}{c}{RMSSE} \\\\\n    \\hline\n    MinT-Struct          & 1.308            & 1.225            & 1.137            & 1.109            & 1.195 \\\\\n    MinT-Shrink         & 1.265            & 1.214            & 1.120            & 1.086            & 1.171 \\\\\n    ML-RF           & 1.261            & \\textbf{1.208}   & 1.104            & 1.066            & 1.159 \\\\\n    ML-XGB          & 1.255            & 1.208            & \\textbf{1.101}   & \\textbf{1.064}   & \\textbf{1.157} \\\\\n    \\hline\n    \\multicolumn{6}{c}{AMSE} \\\\\n    \\hline\n    MinT-Struct          & 0.988            & 0.611            & 0.426            & 0.349            & 0.593 \\\\\n    MinT-Shrink         & 0.935            & 0.599            & 0.417            & 0.337            & 0.572 \\\\\n    ML-RF           & 0.780            & \\textbf{0.526}   & 0.366            & 0.319            & 0.498 \\\\\n    ML-XGB          & \\textbf{0.779}   & 0.526            & \\textbf{0.365}   & \\textbf{0.317}   & \\textbf{0.497}\n  \\end{tabular}\n\n\\begin{textblock}{4.2}(11.2,2.4)\n\\begin{block}{}\\fontsize{11}{11}\\sf\n\\begin{itemize}\\tightlist\n\\item ML methods not significantly different.\n\\item MinT methods significantly different from each other and from ML methods.\n\\end{itemize}\\end{block}\n\\end{textblock}\n\n\n\n\n\n\n\\nocite{htsgeometry, nonnegmint, Di_FonGir2022b, Van_ErvCug2015, lhf}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}