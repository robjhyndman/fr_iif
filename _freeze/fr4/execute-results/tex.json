{
  "hash": "7295e1d8987037896b23761a23a38e6c",
  "result": {
    "markdown": "---\ntitle: Forecast reconciliation\nsubtitle: 4. Probabilistic forecast reconciliation\nauthor: Rob J Hyndman\npdf-engine: pdflatex\nfig-width: 9\nfig-height: 4.5\nformat:\n  beamer:\n    theme: monash\n    aspectratio: 169\n    fontsize: 14pt\n    section-titles: false\n    knitr:\n      opts_chunk:\n        dev: \"CairoPDF\"\ninclude-in-header: header.tex\ncite-method: biblatex\nbibliography: hts.bib\nbiblio-title: References\nkeep-tex: true\nkeep-md: true\nexecute:\n  echo: false\n  message: false\n  warning: false\n  cache: true\n---\n\n::: {.cell}\n\n:::\n\n\n## Outline\n\n\\vspace*{0.4cm}\\tableofcontents\n\n## Notation reminder\n\n* Data: $\\bm{y}_t = \\bm{S}\\bm{b}_t$ where $\\bm{S}$ is a summing matrix and $\\bm{b}_t$ is a vector of disaggregated time series\n* Base forecasts: $\\hat{\\bm{y}}_{T+h|T}$\n* Reconciled forecasts: $\\tilde{\\bm{y}}_{T+h|T}=\\bS\\bm{G}\\hat{\\bm{y}}_{T+h|T}$\n* MinT: $\\bG = (\\bS'\\bm{W}_h^{-1}\\bS)^{-1}\\bS'\\bm{W}_h^{-1}$ where $\\bm{W}_h$ is covariance matrix of base forecast errors.\n\n\n## Probabilistic forecasts\n\n* Gaussian\n* Non-parametric\n* Count\n\n\\nocite{coherentprob,smartmeterhts}\n\n\n## Coherent probabilistic forecasts\n\\begin{textblock}{9.5}(0.2,1.2)\\fontsize{13}{15}\\sf\n\\begin{block}{Coherent probabilistic forecasts}\nGiven the triple $(\\mathbb{R}^m, \\mathscr{F}_{\\mathbb{R}^m}, \\nu)$, a coherent probability triple $(\\mathfrak{s}, \\mathscr{F}_{\\mathfrak{s}}, \\breve{\\nu})$  is such that\n$$\n  \\breve{\\nu}(s(\\mathcal{B})) = \\nu(\\mathcal{B}) \\quad \\forall \\mathcal{B} \\in \\mathscr{F}_{\\mathbb{R}^m}.\n$$\n\\end{block}\\vspace*{-0.2cm}\n\\begin{block}{Probabilistic forecast reconciliation}\nThe reconciled probability measure of $\\hat{\\nu}$ wrt $\\psi(.)$ is such that\n  \\[\n  \\tilde{\\nu}(\\mathcal{B}) = \\hat{\\nu}(\\psi^{-1}(\\mathcal{B})) \\qquad \\forall \\mathcal{B} \\in \\mathscr{F}_{\\mathfrak{s}}\\,,\n  \\]\n  where $\\psi^{-1}(\\mathcal{B}):=\\{{\\bm{y}}\\in \\mathbb{R}^n:\\psi({\\bm{y}})\\in \\mathcal{B}\\}$ is the pre-image of $\\mathcal{B}$, that is the set of all points in $\\mathbb{R}^n$ that $\\psi(.)$ maps to a point in $\\mathcal{B}$.\n\\end{block}\n\\end{textblock}\n\\begin{textblock}{7}(9.5,1.2)\n\\resizebox{\\textwidth}{!}{\n\\input figs/probforerec_schematic.tex\n}\n\\end{textblock}\n\n## Construction of reconciled distributions\n\n\\begin{block}{Reconciled density of bottom-level}\nDensity of bottom-level series under reconciled distribution is\n$$\n  \\tilde{f}_{\\bm{b}}(\\bm{b})=|\\bm{G}^*|\\int \\hat{f}(\\bm{G}^{-}\\bm{b}+\\bm{G}_\\perp \\bm{a})d\\bm{a}\n$$\n\\vspace*{-0.5cm}\\begin{itemize}\n\\item $\\hat{f}$ is density of incoherent base probabilistic forecast\n\\item $\\bm{G^-}$ is $n\\times m$ generalised inverse of $\\bm{G}$ st $\\bm{G}\\bm{G}^-=\\bm{I}$\n\\item $\\bm{G_\\perp}$ is $n\\times (n-m)$ orthogonal complement to $\\bm{G}$ st $\\bm{G}\\bm{G}_\\perp=\\bm{0}$\n\\item $\\bm{G}^*=\\left(\\bm{G}^-\\,\\vdots\\,\\bm{G}_\\perp\\right)$, and $\\bm{b}$ and $\\bm{a}$ are obtained via\\newline the change of variables $\\bm{y}=\\bm{G}^*\\begin{pmatrix}\\bm{b}\\\\\\bm{a}\\end{pmatrix}$\n\\end{itemize}\n\\end{block}\n\\vspace*{10cm}\n\n## Construction of reconciled distributions\n\n\\begin{block}{Reconciled density of full hierarchy}\\fontsize{14}{15}\\sf\nDensity of full hierarchy under reconciled distribution is\n$$\n  \\tilde{f}_{\\bm{y}}(\\bm{y}) =\n  |\\bm{S}^*| \\tilde{f}_{\\bm{b}}({\\bm{S}^-\\bm{y}})\n  \\mathbb{1}\\{\\bm{y}\\in\\mathfrak{s}\\}\n$$\n\\vspace*{-0.5cm}\\begin{itemize}\n\\item $\\bm{S}^*=\\begin{pmatrix}\n  \\bm{S}^-\\\\\n  \\bm{S}'_\\perp\n  \\end{pmatrix}$\n\\item $\\bm{S^-}$ is $m\\times n$ generalised inverse of $\\bm{S}$ such that $\\bm{S}^-\\bm{S}=\\bm{I}$,\n\\item $\\bm{S_\\perp}$ is $n\\times (n-m)$ orthogonal complement to $\\bm{S}$ such that $\\bm{S}'_\\perp\\bm{S}=\\bm{0}$.\n\\end{itemize}\n\\end{block}\\pause\n\n\\begin{alertblock}{Gaussian reconciliation}\nIf the incoherent base forecasts are $\\text{N}(\\hat{\\bm{\\mu}}, \\hat{\\bm{\\Sigma}})$,\\newline\nthen the reconciled density is $\\text{N}(\\bm{S}\\bm{G}\\hat{\\bm{\\mu}}, \\bm{S}\\bm{G}\\hat{\\bm{\\Sigma}}\\bm{G}'\\bm{S}')$.\n\\end{alertblock}\n\n## Simulation from a reconciled distribution\n\n\\begin{block}{}\nSuppose that $\\left(\\hat{\\bm{y}}^{[1]},\\ldots,\\hat{\\bm{y}}^{[L]}\\right)$ is a sample drawn from an incoherent probability measure $\\hat{\\nu}$. Then $\\left(\\tilde{\\bm{y}}^{[1]},\\ldots,\\tilde{\\bm{y}}^{[L]}\\right)$ where $\\tilde{\\bm{y}}^{[\\ell]}:=\\psi(\\hat{\\bm{y}}^{[\\ell]})$ for $\\ell=1,\\ldots,L$, is a sample drawn from the reconciled probability measure $\\tilde{\\nu}$.\n\\end{block}\n\n* So reconciling sample paths from incoherent distributions works.\n\n\\vspace*{10cm}\n\n\n\n\n\n# Evaluating probabilistic forecasts\n\n## Evaluating probabilistic forecasts\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-3_a8ba8e65e4270b68a42d666589e3e7db'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/unnamed-chunk-3-1.pdf)\n:::\n:::\n\n\n## Evaluating probabilistic forecasts\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-4_13d3a6cafc223362b0c0e0eeef955298'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/unnamed-chunk-4-1.pdf)\n:::\n:::\n\n\n## Evaluating probabilistic forecasts\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-5_9be6090cd46e0092736e0c933ff2fc46'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/unnamed-chunk-5-1.pdf)\n:::\n:::\n\n\n## Evaluating probabilistic forecasts\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-6_fd24b1694a17e4d081c87258835c11e9'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/unnamed-chunk-6-1.pdf)\n:::\n:::\n\n\n## Evaluating probabilistic forecasts\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-7_52b1194e97cc6c5302c531b5fafd6c3f'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/unnamed-chunk-7-1.pdf)\n:::\n:::\n\n\n## Evaluating probabilistic forecasts\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-8_515d441508e951656190d1a32b10bb7e'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/unnamed-chunk-8-1.pdf)\n:::\n:::\n\n\n## Evaluating probabilistic forecasts\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-9_24a4d2a6c4e300153c5ebac9e75906f6'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/unnamed-chunk-9-1.pdf)\n:::\n:::\n\n\n## Evaluating probabilistic forecasts\n\n\n::: {.cell hash='fr4_cache/beamer/pinball_4a0e4e257cf4eefe6d52a4091c589044'}\n\n:::\n\n\n\\fontsize{12}{13}\\sf\n\\begin{textblock}{8}(0.2,1.2)\n\\begin{alertblock}{}\\vspace*{-0.3cm}\n\\begin{align*}\nq_{p,t} &= \\text{quantile forecast with prob. $p$ at time $t$.}\\\\\ny_{t} &= \\text{observation at time $t$}\n\\end{align*}\n\\end{alertblock}\\vspace*{-0.3cm}\n\\begin{block}{Quantile score}\\vspace*{-0.1cm}\n$$\n  S_t(p,y) = \\begin{cases}\n  2(1 - p) \\big|y_t - q_{p,t}\\big|, & \\text{if $y_{t} < q_{p,t}$}\\\\\n  2p \\big|y_{t} - q_{p,t}\\big|, & \\text{if $y_{t} \\ge q_{p,t}$} \\end{cases}\n$$\n\\end{block}\n\\end{textblock}\n\\begin{textblock}{8}(0.2,5.)\n\\begin{itemize}\\itemsep=0cm\\parskip=0cm\n\\item Low $S_{t}$ is good\n\\item Multiplier of 2 often omitted,\\newline but useful for interpretation\n\\item $S_{t}$ like absolute error,\\newline weighted to account for likely exceedance\n\\item Average $S_{t}(p,y)$ over $p$ = \\newline CRPS (Continuous Rank Probability Score)\n\\end{itemize}\n\\end{textblock}\n\\placefig{8.7}{1.4}{width=7.3cm}{deciles.pdf}\n\n<!-- \\begin{textblock}{1}(8.5,5.1) -->\n<!-- \\animategraphics[loop,autoplay,width=7.4cm]{10}{fr4_files/figure-beamer/pinball-}{1}{100} -->\n<!-- \\end{textblock} -->\n\n## Evaluating probabilistic forecasts\n\n### Continuous Rank Probability Score (univariate forecsts)\n\nForecast distribution $F_t$ and observation $y_t$.\n$$\n\\text{CRPS}(F_t,y_t)~  = \\int_{0}^1 S_{p,t}(p,y_t) dp ~  = ~\\text{E}_F|Y-y_t|-\\frac{1}{2}\\text{E}_F|Y-Y^*|\n$$\n\n * $Y$ and $Y^*$ are iid draws from $F_t$.\n * Optimal when $F_t$ is true distribution (i.e., it is a proper score)\n\n\\pause\n\n### Energy score (multivariate forecasts)\n\n * $\\text{ES}(F_t,\\bm{y}_t) = \\E_{F} ||{\\bm{Y}}-\\bm{y}_t|| -\\frac{1}{2}\\E_{F}||\\bm{Y}-\\bm{Y}^*||$\n\n\\pause\n\n### Log score (multivariate forecasts)\n\n * $\\text{LS}(F_t, \\bm{y}_t) = -\\log f(\\bm{y}_t)$\n\n## Evaluating probabilistic forecasts\n\\vspace*{-0.1cm}\n\n\\begin{alertblock}{Proper scoring rule}\noptimized when true forecast distribution is used.\n\\end{alertblock}\\pause\\vspace*{-0.1cm}\n\n\\begin{block}{}\\centering\n\\begin{tabular}{llp{4.4cm}}\n    \\bfseries Scoring Rule &\n    \\bfseries Coherent v Incoherent &\n    \\bfseries Coherent v Coherent\\\\\n    \\midrule\n    Log Score & Not proper & $\\bullet$ Ordering preserved\\par\\hspace*{0.3cm} if compared using\\par\\hspace*{0.3cm} bottom-level only\\\\\n    Energy Score & Proper & $\\bullet$ Full hierarchy\\par\\hspace*{0.3cm} should be used. \\par $\\bullet$ Rankings may\\par\\hspace*{0.3cm} change otherwise.\n\\end{tabular}\n\\end{block}\n\n## Score optimal reconciliation\n\nAlgorithm proposed by Panagiotelis et al (2020) for optimizing $\\bm{G}$ using stochastic gradient descent to optimize Energy Score.\n\n1. Compute base forecasts over a test set.\n2. Compute OLS reconciliation: $\\bm{G} = (\\bm{S}'\\bm{S})^{-1}\\bm{S}'$\n3. Iteratively update $\\bm{G}$ using SGD with Adam method and ES objective over a test set\n\n# Example: Australian tourism\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/tourismdata_53fbaaf45732879c2d166d537eda6600'}\n\n```{.r .cell-code}\ntourism\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 24,320 x 5 [1Q]\n# Key:       Region, State, Purpose [304]\n   Quarter Region   State           Purpose  Trips\n     <qtr> <chr>    <chr>           <chr>    <dbl>\n 1 1998 Q1 Adelaide South Australia Business  135.\n 2 1998 Q2 Adelaide South Australia Business  110.\n 3 1998 Q3 Adelaide South Australia Business  166.\n 4 1998 Q4 Adelaide South Australia Business  127.\n 5 1999 Q1 Adelaide South Australia Business  137.\n 6 1999 Q2 Adelaide South Australia Business  200.\n 7 1999 Q3 Adelaide South Australia Business  169.\n 8 1999 Q4 Adelaide South Australia Business  134.\n 9 2000 Q1 Adelaide South Australia Business  154.\n10 2000 Q2 Adelaide South Australia Business  169.\n# i 24,310 more rows\n```\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/tourismagg_8bc83189f90b5443d19a35af16a4c6ab'}\n\n```{.r .cell-code}\ntourism_agg <- tourism |>\n  aggregate_key(State/Region * Purpose, Trips = sum(Trips))\n```\n:::\n\n::: {.cell hash='fr4_cache/beamer/tourismagg2_9766d6ca0b258ff502b41fda18e4336a'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 34,000 x 5 [1Q]\n# Key:       State, Purpose, Region [425]\n   Quarter State        Purpose      Region        Trips\n     <qtr> <chr*>       <chr*>       <chr*>        <dbl>\n 1 1998 Q1 <aggregated> <aggregated> <aggregated> 23182.\n 2 1998 Q2 <aggregated> <aggregated> <aggregated> 20323.\n 3 1998 Q3 <aggregated> <aggregated> <aggregated> 19827.\n 4 1998 Q4 <aggregated> <aggregated> <aggregated> 20830.\n 5 1999 Q1 <aggregated> <aggregated> <aggregated> 22087.\n 6 1999 Q2 <aggregated> <aggregated> <aggregated> 21458.\n 7 1999 Q3 <aggregated> <aggregated> <aggregated> 19914.\n 8 1999 Q4 <aggregated> <aggregated> <aggregated> 20028.\n 9 2000 Q1 <aggregated> <aggregated> <aggregated> 22339.\n10 2000 Q2 <aggregated> <aggregated> <aggregated> 19941.\n# i 33,990 more rows\n```\n:::\n:::\n\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/tourismmodels_1a5fe1d887520e7c7b31fd6ab7377941'}\n\n```{.r .cell-code}\nfit <- tourism_agg |>\n  filter(year(Quarter) <= 2015) |>\n  model(ets = ETS(Trips))\n```\n:::\n\n::: {.cell hash='fr4_cache/beamer/tourismmodels1_c6cd8252f972171f63ffd27d2539dde1'}\n::: {.cell-output .cell-output-stdout}\n```\n# A mable: 425 x 4\n# Key:     State, Purpose, Region [425]\n   State  Purpose      Region                ets\n   <chr*> <chr*>       <chr*>            <model>\n 1 ACT    Business     Canberra     <ETS(M,N,M)>\n 2 ACT    Business     <aggregated> <ETS(M,N,M)>\n 3 ACT    Holiday      Canberra     <ETS(M,N,A)>\n 4 ACT    Holiday      <aggregated> <ETS(M,N,A)>\n 5 ACT    Other        Canberra     <ETS(M,N,N)>\n 6 ACT    Other        <aggregated> <ETS(M,N,N)>\n 7 ACT    Visiting     Canberra     <ETS(A,N,N)>\n 8 ACT    Visiting     <aggregated> <ETS(A,N,N)>\n 9 ACT    <aggregated> Canberra     <ETS(A,N,N)>\n10 ACT    <aggregated> <aggregated> <ETS(A,N,N)>\n# i 415 more rows\n```\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fctourism_b360b61005537641a66c19a24dfd0b68'}\n\n```{.r .cell-code}\nfc <- fit |>\n  reconcile(ets_adjusted = min_trace(ets)) |>\n  forecast(h = \"2 years\")\n```\n:::\n\n::: {.cell hash='fr4_cache/beamer/fctourism1_7358c3de1ae57fd2b7f2667eb4e6f4d4'}\n::: {.cell-output .cell-output-stdout}\n```\n# A fable: 6,800 x 7 [1Q]\n# Key:     State, Purpose, Region, .model [850]\n   State  Purpose  Region   .model       Quarter        Trips .mean\n   <chr*> <chr*>   <chr*>   <chr>          <qtr>       <dist> <dbl>\n 1 ACT    Business Canberra ets          2016 Q1  N(111, 669)  111.\n 2 ACT    Business Canberra ets          2016 Q2 N(156, 1312)  156.\n 3 ACT    Business Canberra ets          2016 Q3 N(156, 1320)  156.\n 4 ACT    Business Canberra ets          2016 Q4 N(152, 1248)  152.\n 5 ACT    Business Canberra ets          2017 Q1  N(111, 669)  111.\n 6 ACT    Business Canberra ets          2017 Q2 N(156, 1312)  156.\n 7 ACT    Business Canberra ets          2017 Q3 N(156, 1320)  156.\n 8 ACT    Business Canberra ets          2017 Q4 N(152, 1248)  152.\n 9 ACT    Business Canberra ets_adjusted 2016 Q1  N(116, 328)  116.\n10 ACT    Business Canberra ets_adjusted 2016 Q2  N(166, 548)  166.\n# i 6,790 more rows\n```\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fctourism2_7b94f76128b81d3578799a98b97b1d6d'}\n\n```{.r .cell-code}\nfc |>\n  filter(is_aggregated(State) & is_aggregated(Purpose)) |>\n  autoplot(filter(tourism_agg, year(Quarter) > 2012), level = 95)\n```\n\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/fctourism2-1.pdf)\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fctourism3_efdfa45dcc8518d35f86012e8be2be8d'}\n\n```{.r .cell-code}\nfc |>\n  filter(State == \"New South Wales\" & is_aggregated(Region) & is_aggregated(Purpose)) |>\n  autoplot(filter(tourism_agg, year(Quarter) > 2012), level = 95)\n```\n\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/fctourism3-1.pdf)\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fctourism4_8bafd9e94e3680c0e7e288a471dbf70a'}\n\n```{.r .cell-code}\nfc |>\n  filter(Region == \"Melbourne\" & is_aggregated(Purpose)) |>\n  autoplot(filter(tourism_agg, year(Quarter) > 2012), level = 95)\n```\n\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/fctourism4-1.pdf)\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fctourism5_3fa02774775908449f6a56a8b0ce946b'}\n\n```{.r .cell-code}\nfc |>\n  filter(Region == \"Snowy Mountains\", Purpose == \"Holiday\") |>\n  autoplot(filter(tourism_agg, year(Quarter) > 2012), level = 95)\n```\n\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/fctourism5-1.pdf)\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fctourism6_cfd9df1aa4148583431ffbd6afc1ebb2'}\n\n```{.r .cell-code}\nfc |>\n  filter(Region == \"Barossa\") |>\n  autoplot(filter(tourism_agg, year(Quarter) > 2012), level = 95)\n```\n\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/fctourism6-1.pdf)\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fctourism7_1a4e92e71eff755dfbdbbb39fc0aa48d'}\n\n```{.r .cell-code}\nfc |>\n  filter(Region == \"MacDonnell\") |>\n  autoplot(filter(tourism_agg, year(Quarter) > 2012), level = 95)\n```\n\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/fctourism7-1.pdf)\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fctourismcomb_ff08d3544c9a14db606b92fa9c948c1d'}\n\n```{.r .cell-code}\nfc <- tourism_agg |>\n  filter(year(Quarter) <= 2015) |>\n  model(\n    ets = ETS(Trips),\n    arima = ARIMA(Trips)\n  ) |>\n  mutate(\n    comb = (ets + arima) / 2\n  ) |>\n  reconcile(\n    ets_adj = min_trace(ets),\n    arima_adj = min_trace(arima),\n    comb_adj = min_trace(comb)\n  ) |>\n  forecast(h = \"2 years\")\n```\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fcaccuracy_590bac0eeacfc4105caef75aab2b6a86'}\n\n```{.r .cell-code}\nfc |>\n  accuracy(data = tourism_agg,\n           measures = list(crps = CRPS, ss=skill_score(CRPS)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,550 x 7\n   .model State  Purpose      Region       .type   crps      ss\n   <chr>  <chr*> <chr*>       <chr*>       <chr>  <dbl>   <dbl>\n 1 arima  ACT    Business     Canberra     Test   25.2   0.229 \n 2 arima  ACT    Business     <aggregated> Test   25.2   0.229 \n 3 arima  ACT    Holiday      Canberra     Test   33.5   0.103 \n 4 arima  ACT    Holiday      <aggregated> Test   33.5   0.103 \n 5 arima  ACT    Other        Canberra     Test    9.97  0.0684\n 6 arima  ACT    Other        <aggregated> Test    9.97  0.0684\n 7 arima  ACT    Visiting     Canberra     Test   34.7  -0.0985\n 8 arima  ACT    Visiting     <aggregated> Test   34.7  -0.0985\n 9 arima  ACT    <aggregated> Canberra     Test  106.   -0.633 \n10 arima  ACT    <aggregated> <aggregated> Test  106.   -0.633 \n# i 2,540 more rows\n```\n:::\n:::\n\n\n## Example: Australian tourism\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/fcaccuracy2_948de5a26157c50bfc3abe87a4019050'}\n\n```{.r .cell-code}\nfc |>\n  accuracy(tourism_agg,\n           measures = list(crps = CRPS, ss=skill_score(CRPS))) |>\n  group_by(.model) |>\n  summarise(sspc = mean(ss) * 100) |>\n  arrange(sspc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 2\n  .model     sspc\n  <chr>     <dbl>\n1 arima      4.05\n2 arima_adj  4.16\n3 comb_adj   8.69\n4 comb       8.93\n5 ets_adj    9.41\n6 ets        9.45\n```\n:::\n:::\n\n\n\n# Example: Australian electricity generation\n\n## Example: Australian electricity generation\n\n\\begin{block}{Daily time series from \\url{opennem.org.au}}\n\\begin{enumerate}\n\\item\n  Total = Renewable + Non-renewable\n\\item\n  Renewable = Batteries + Hydro + Solar + Wind + Biomass\\\\\n  Non-Renewable = Coal + Gas + Distillate\n\\item\n  Battery = Battery (Discharging) + Battery (Charging)\\\\\n  Solar = Solar (Rooftop) + Solar (Utility)\\\\\n  Coal = Black Coal + Brown Coal\\\\\n  Gas = Gas (OCGT) + Gas (CCGT) + Gas (Steam) + Gas (Recip)\n\\end{enumerate}\n\\end{block}\n\n$n=23$ series; $m=15$ bottom-level series.\n\n## Example: Australian electricity generation\n\n\n\n\n::: {.cell hash='fr4_cache/beamer/selected_30ab42cf64c5f078cbcdd13ca1ab2a6c'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/selected-1.pdf)\n:::\n:::\n\n\n## Example: Australian electricity generation\n\n\\alert{Forecast evaluation}\n\n * Rolling window of 140 days training data, and one-step-forecasts for 170 days test data.\n * One-layer feed-forward neural network with up to 28 lags of target variable as inputs.\n * Implemented using `NNETAR()` function in `fable` package.\n * Model could be improved with temperature predictor.\n\n## Example: Australian electricity generation\n\n\\placefig{0.3}{1.5}{width=7.5cm, height=10cm}{densities}\n\\begin{textblock}{6}(9,1.7)\n\\begin{block}{Histogram of residuals:\\\\ 2 Oct 2019 -- 21 Jan 2020}\nClearly non-Gaussian\n\\end{block}\n\\end{textblock}\n\n## Example: Australian electricity generation\n\n\\placefig{0.3}{1.5}{width=7.7cm, height=10cm}{corr}\n\n\\begin{textblock}{6}(9,1.7)\n\\begin{block}{Correlations of residuals:\\\\ 2 Oct 2019 -- 21 Jan 2020}\nBlue = positive correlation. Red = negative correlation. Large = stronger correlations.\n\\end{block}\n\\end{textblock}\n\n\n## Example: Australian electricity generation\n\n\\placefig{0.3}{1.5}{width=7.2cm, height=10cm}{meanenergyscore}\n\n\\begin{textblock}{3.5}(2.5,1.4)\\fontsize{12}{12.5}\\sf\n\\begin{block}{}\nMean Energy score\n\\end{block}\n\\end{textblock}\n\n\\begin{textblock}{7}(8.7,1.3)\\fontsize{12}{12.5}\\sf\n\\begin{block}{Base residual assumptions}\n\\begin{itemize}\\itemsep=0cm\\parskip=0cm\n\\item Gaussian independent\n\\item Gaussian dependent\n\\item Non-Gaussian independent\n\\item Non-Gaussian dependent\n\\end{itemize}\n\\end{block}\\vspace*{-0.1cm}\n\\begin{block}{Reconciliation methods}\n\\begin{itemize}\\itemsep=0cm\\parskip=0cm\n\\item Base\n\\item BottomUp\n\\item BTTH: Ben Taieb, Taylor, Hyndman\n\\item JPP: Jeon, Panagiotelis, Petropoulos\n\\item OLS\n\\item MinT(Shrink)\n\\item Score Optimal Reconciliation\n\\end{itemize}\n\\end{block}\n\\end{textblock}\n\n\n## Example: Australian electricity generation\n\n\\placefig{0.3}{1.5}{width=6.cm, height=10cm}{nemenyi_ig}\n\n\\placefig{8.3}{1.5}{width=6.cm, height=10cm}{nemenyi_jb}\n\n\\begin{textblock}{7}(0.2,7.)\\fontsize{11}{12}\\sf\n\\begin{block}{Nemenyi test for different scores}\nBase forecasts are independent and Gaussian.\n\\end{block}\n\\end{textblock}\n\n\\begin{textblock}{7}(8.8,7.)\\fontsize{11}{12}\\sf\n\\begin{block}{Nemenyi test for different scores}\nBase forecasts are obtained by jointly bootstrapping residuals.\n\\end{block}\n\\end{textblock}\n\n\n## Probabilistic forecast reconciliation\n\n\\begin{block}{Key papers}\n\\begin{itemize}\n\\item Ben Taieb, Taylor, Hyndman (\\emph{ICML}, 2017)\n\\item Jeon, Panagiotelis, Petropoulos (\\emph{EJOR}, 2019)\n\\item Ben Taieb, Taylor, Hyndman (\\emph{JASA}, 2020)\n\\item Panagiotelis, Gamakumara, Athanasopoulos, Hyndman (2020). \\url{robjhyndman.com/publications/coherentprob/}\n\\end{itemize}\n\\end{block}\\pause\\vspace*{-0.2cm}\n\n * The reconciled multivariate density must lie on the coherent subspace.\n * The univariate density at each node is a convolution of the densities of its children.\n\n## Construction of reconciled distributions\n\n\\begin{block}{Reconciled density of bottom-level}\nDensity of bottom-level series under reconciled distribution is\n$$\n  \\tilde{f}_{\\bm{b}}(\\bm{b})=|\\bG^*|\\int \\hat{f}(\\bG^{-}\\bm{b}+\\bG_\\perp \\bm{a})d\\bm{a}\n$$\n\\vspace*{-0.5cm}\\begin{itemize}\n\\item $\\hat{f}$ is density of incoherent base probabilistic forecast\n\\item $\\bm{G^-}$ is $n\\times m$ generalised inverse of $\\bG$ st $\\bG\\bG^-=\\bm{I}$\n\\item $\\bm{G_\\perp}$ is $n\\times (n-m)$ orthogonal complement to $\\bG$ st $\\bG\\bG_\\perp=\\bm{0}$\n\\item $\\bG^*=\\left(\\bG^-\\,\\vdots\\,\\bG_\\perp\\right)$, and $\\bm{b}$ and $\\bm{a}$ are obtained via\\newline the change of variables $\\bm{y}=\\bG^*\\begin{pmatrix}\\bm{b}\\\\\\bm{a}\\end{pmatrix}$\n\\end{itemize}\n\\end{block}\n\\vspace*{10cm}\n\n## Construction of reconciled distributions\n\n\\begin{block}{Reconciled density of full hierarchy}\\fontsize{14}{15}\\sf\nDensity of full hierarchy under reconciled distribution is\n$$\n  \\tilde{f}_{\\bm{y}}(\\bm{y}) =\n  |\\bS^*|\n  \\,\n  \\tilde{f}_{\\bm{b}}({\\bS^-\\bm{y}})\n  \\,\n  \\mathbb{1}\\!\\{\\bm{y}\\in\\mathfrak{s}\\}\n$$\n\\vspace*{-0.6cm}\\begin{itemize}\n\\item $\\bS^*=\\begin{pmatrix} {\\bS^-}' & \\bS_\\perp \\end{pmatrix}'$\n\\item $\\bm{S^-}$ is $m\\times n$ generalised inverse of $\\bS$ such that $\\bS^-\\bS=\\bm{I}$,\n\\item $\\bm{S_\\perp}$ is $n\\times (n-m)$ orthogonal complement to $\\bS$ such that $\\bS'_\\perp\\bS=\\bm{0}$.\n\\end{itemize}\n\\end{block}\n\n\\begin{textblock}{7.7}(0.4,5.8)\n\\begin{alertblock}{Gaussian reconciliation}\nIf the incoherent base forecasts are $\\text{N}(\\hat{\\bm{\\mu}}, \\hat{\\bm{\\Sigma}})$,\nthen the reconciled density is $\\text{N}(\\bS\\bG\\hat{\\bm{\\mu}}, \\bS\\bG\\hat{\\bm{\\Sigma}}\\bG'\\bS')$.\n\\end{alertblock}\n\\end{textblock}\n\n\\begin{textblock}{6.8}(8.8,5.8)\n\\begin{alertblock}{Bootstrap reconciliation}\nReconciling sample paths from incoherent distributions works.\n\\end{alertblock}\n\\end{textblock}\n\n\\vspace*{10cm}\n\n## Evaluating probabilistic forecasts\n\n\\begin{alertblock}{Proper scoring rule}\noptimized when true forecast distribution is used.\n\\end{alertblock}\\pause\n\n\\begin{block}{}\\centering\\fontsize{14}{15}\\sf\n\\begin{tabular}{llp{4.4cm}}\n    \\bfseries Scoring Rule &\n    \\bfseries Coherent v Incoherent &\n    \\bfseries Coherent v Coherent\\\\\n    \\midrule\n    Log Score & Not proper & $\\bullet$ Ordering preserved\\par\\hspace*{0.3cm} if compared using\\par\\hspace*{0.3cm} bottom-level only\\\\\n    \\midrule\n    Energy Score & Proper & $\\bullet$ Full hierarchy\\par\\hspace*{0.3cm} should be used. \\par $\\bullet$ Rankings may\\par\\hspace*{0.3cm} change otherwise.\n\\end{tabular}\n\\end{block}\n\n## Score optimal reconciliation\n\nAlgorithm proposed by Panagiotelis et al (2020) for optimizing $\\bG$ using stochastic gradient descent to optimize Energy Score.\n\n1. Compute base forecasts over a test set.\n2. Compute OLS reconciliation: $\\bG = (\\bS'\\bS)^{-1}\\bS'$\n3. Iteratively update $\\bG$ using SGD with Adam method and ES objective over a test set\n\n# Example: Australian electricity generation\n\n## Example: Australian electricity generation\n\n\\hspace*{-0.8cm}\\begin{minipage}{15.6cm}\n\\begin{block}{Daily time series from \\url{opennem.org.au}}\n\\begin{tikzpicture}\n\\tikzstyle{every node}=[rectangle, rounded corners=2pt,draw,inner sep=1pt,fill=red!15]\n\\tikzstyle[level distance=.1cm]\n\\tikzstyle[sibling distance=7cm]\n\\tikzstyle{level 1}=[sibling distance=8.2cm,set style={{every node}+=[fill=blue!15]}]\n\\tikzstyle{level 2}=[sibling distance=16.5mm,font=\\footnotesize,set style={{every node}+=[fill=green!15]}]\n\\tikzstyle{level 3}=[sibling distance=10mm,font=\\footnotesize,set style={{every node}+=[fill=yellow]}]\n\\node{Total generation}[edge from parent fork down]\n child {node {Renewable}\n   child {node[xshift=0.2cm] {Batteries}\n    child {node[xshift=-0.3cm] {Discharging}}\n    child {node[xshift=0.3cm] {Charging}}\n   }\n   child {node[fill=yellow] {Wind}}\n   child {node {Hydro+Pumps}\n     child {node {Hydro}}\n     child {node {Pumps}}\n   }\n   child {node[xshift=0.2cm,fill=yellow] {Biomass}}\n   child {node[xshift=-0.2cm] {Solar}\n     child {node {Rooftop}}\n     child {node[xshift=0.1cm] {Utility}}\n   }\n }\n child {node {Non-renewable}\n   child {node {Gas}\n     child {node {OCGT}}\n     child {node {CCGT}}\n     child {node {Steam}}\n     child {node {Recip}}\n   }\n   child {node[fill=yellow] {Distillate}}\n   child {node {Coal}\n     child {node {Black}}\n     child {node {Brown}}\n   }\n };\n\\end{tikzpicture}\n\\end{block}\n\\end{minipage}\n\n\\begin{textblock}{10}(3,7.8)\n\\begin{block}{}\\vspace*{-0.1cm}\n\\centerline{$n=23$ series\\qquad $m=15$ bottom-level series}\n\\end{block}\n\\end{textblock}\n\n## Example: Australian electricity generation\n\n\n\n\n::: {.cell hash='fr4_cache/beamer/selected2_f0c549128606750ded56d6e1d239db2c'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/selected2-1.pdf)\n:::\n:::\n\n\n## Example: Australian electricity generation\n\n\\alert{Forecast evaluation}\n\n * Rolling window of 140 days training data, and one-step-forecasts for 170 days test data.\n * One-layer feed-forward neural network with up to 28 lags of target variable as inputs.\n * Implemented using `NNETAR()` function in `fable` package.\n * Model could be improved with temperature predictor.\n\n## Example: Australian electricity generation\n\n\\placefig{0.3}{1.5}{width=7.5cm, height=10cm}{densities}\n\\begin{textblock}{6}(9,1.7)\n\\begin{block}{Histogram of residuals:\\\\ 2 Oct 2019 -- 21 Jan 2020}\nClearly non-Gaussian\n\\end{block}\n\\end{textblock}\n\n## Example: Australian electricity generation\n\n\\placefig{0.3}{1.5}{width=7.7cm, height=10cm}{corr}\n\n\\begin{textblock}{6}(9,1.7)\n\\begin{block}{Correlations of residuals:\\\\ 2 Oct 2019 -- 21 Jan 2020}\nBlue = positive correlation. Red = negative correlation. Large = stronger correlations.\n\\end{block}\n\\end{textblock}\n\n## Example: Australian electricity generation\n\n\\placefig{0.3}{1.5}{width=7.2cm, height=10cm}{meanenergyscore}\n\n\\begin{textblock}{3.5}(2.5,1.4)\\fontsize{12}{12.5}\\sf\n\\begin{block}{}\nMean Energy score\n\\end{block}\n\\end{textblock}\n\n\\begin{textblock}{7}(8.7,1.3)\\fontsize{12}{12.5}\\sf\n\\begin{block}{Base residual assumptions}\n\\begin{itemize}\\itemsep=0cm\\parskip=0cm\n\\item Gaussian independent\n\\item Gaussian dependent\n\\item Non-Gaussian independent\n\\item Non-Gaussian dependent\n\\end{itemize}\n\\end{block}\\vspace*{-0.1cm}\n\\begin{block}{Reconciliation methods}\n\\begin{itemize}\\itemsep=0cm\\parskip=0cm\n\\item Base\n\\item BottomUp\n\\item BTTH: Ben Taieb, Taylor, Hyndman\n\\item JPP: Jeon, Panagiotelis, Petropoulos\n\\item OLS\n\\item MinT(Shrink)\n\\item Score Optimal Reconciliation\n\\end{itemize}\n\\end{block}\n\\end{textblock}\n\n## Example: Australian electricity generation\n\n\\placefig{0.3}{1.5}{width=6.cm, height=10cm}{nemenyi_ig}\n\n\\placefig{8.3}{1.5}{width=6.cm, height=10cm}{nemenyi_jb}\n\n\\begin{textblock}{7}(0.2,7.)\\fontsize{11}{12}\\sf\n\\begin{block}{Nemenyi test for different scores}\nBase forecasts are independent and Gaussian.\n\\end{block}\n\\end{textblock}\n\n\\begin{textblock}{7}(8.8,7.)\\fontsize{11}{12}\\sf\n\\begin{block}{Nemenyi test for different scores}\nBase forecasts are obtained by jointly bootstrapping residuals.\n\\end{block}\n\\end{textblock}\n\n# Emergency Services Demand\n\n## Wales Health Board Areas\n\n\\placefig{3.3}{1.2}{width=7.8cm}{Map-of-Wales-Health-Boards}\n\n## Data\n\n\n::: {.cell hash='fr4_cache/beamer/data_1446b1f644d15a01bb171118b3a6f050'}\n\n:::\n\n\n\n\n* Daily number of attended incidents:\\newline 1 October 2015 -- 31 July 2019\n* Disaggregated by:\n  * control area\n  * health board\n  * priority\n  * nature of incidents\n* 2,142,000 rows observations from 1,530 time series.\n\n## Data structure\n\n\n\n\n\n\\placefig{0.3}{1.5}{width=7cm}{group.pdf}\n\\placefig{7.5}{1.5}{width=7.7cm}{group.png}\n\n## Data structure\n\\fontsize{10}{11}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/data_structure_table_bbf6d4dd71b531b94ec85a1f39716848'}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\begin{tabular}{lr}\n\\toprule\nLevel & Number of series\\\\\n\\midrule\nAll country & 1\\\\\nControl & 3\\\\\nHealth board & 7\\\\\nPriority & 3\\\\\nPriority * Control & 9\\\\\nPriority * Health board & 21\\\\\nNature of incident & 35\\\\\nNature of incident * Control & 105\\\\\nNature of incident * Health board & 245\\\\\nPriority * Nature of incident & 104\\\\\nControl * Priority * Nature of incident & 306\\\\\nControl * Health board * Priority * Nature of incident (Bottom level) & 691\\\\\nTotal & 1530\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n## Data\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-16_0fc7a140ec2a571be80db8b72c1863f2'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 2,142,000 x 6 [1D]\n# Key:       region, category, nature, lhb [1,530]\n   date       region       category     nature       lhb          incident\n   <date>     <chr*>       <chr*>       <chr*>       <chr*>          <dbl>\n 1 2015-10-01 <aggregated> <aggregated> <aggregated> <aggregated>     1020\n 2 2015-10-02 <aggregated> <aggregated> <aggregated> <aggregated>     1021\n 3 2015-10-03 <aggregated> <aggregated> <aggregated> <aggregated>     1025\n 4 2015-10-04 <aggregated> <aggregated> <aggregated> <aggregated>     1043\n 5 2015-10-05 <aggregated> <aggregated> <aggregated> <aggregated>     1067\n 6 2015-10-06 <aggregated> <aggregated> <aggregated> <aggregated>     1063\n 7 2015-10-07 <aggregated> <aggregated> <aggregated> <aggregated>      973\n 8 2015-10-08 <aggregated> <aggregated> <aggregated> <aggregated>     1057\n 9 2015-10-09 <aggregated> <aggregated> <aggregated> <aggregated>     1026\n10 2015-10-10 <aggregated> <aggregated> <aggregated> <aggregated>     1063\n# i 2,141,990 more rows\n```\n:::\n:::\n\n\n## Data\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-17_392168137ff29a0f037916753f023ca8'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tsibble: 2,142,000 x 6 [1D]\n# Key:       region, category, nature, lhb [1,530]\n   date       region category nature    lhb          incident\n   <date>     <chr*> <chr*>   <chr*>    <chr*>          <dbl>\n 1 2015-10-01 C      Amber    ABDOMINAL HD                  0\n 2 2015-10-01 C      Amber    ABDOMINAL PO                  0\n 3 2015-10-01 C      Amber    ABDOMINAL SB                  0\n 4 2015-10-01 C      Amber    ABDOMINAL <aggregated>        0\n 5 2015-10-01 C      Amber    ALLERGIES HD                  0\n 6 2015-10-01 C      Amber    ALLERGIES PO                  1\n 7 2015-10-01 C      Amber    ALLERGIES SB                  0\n 8 2015-10-01 C      Amber    ALLERGIES <aggregated>        1\n 9 2015-10-01 C      Amber    ANIMALBIT HD                  0\n10 2015-10-01 C      Amber    ANIMALBIT PO                  0\n# i 2,141,990 more rows\n```\n:::\n:::\n\n::: {.cell hash='fr4_cache/beamer/time_plots_45af966c183e4e5333b700cf9c7ad286'}\n\n:::\n\n\n## Aggregated daily incidents\n\n\n::: {.cell hash='fr4_cache/beamer/time_plots1_959290ff244eeb9dca59d8b52936cf66'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/time_plots1-1.pdf)\n:::\n:::\n\n\n## Daily incidents by control area\n\n\n::: {.cell hash='fr4_cache/beamer/time_plots2_e7eaa6e829f0496178f6966b43c9f87a'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/time_plots2-1.pdf)\n:::\n:::\n\n\n## Data incidents by health board\n\n\n::: {.cell hash='fr4_cache/beamer/time_plots3_aa6b4bc45ccd41041bc6511aa0d96f8d'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/time_plots3-1.pdf)\n:::\n:::\n\n\n## Data incidents by priority\n\n\n::: {.cell hash='fr4_cache/beamer/time_plots4_1517164f5e882bc85baf0a070e7dbe2c'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/time_plots4-1.pdf)\n:::\n:::\n\n\n## Data incidents by nature of incident\n\n\n::: {.cell hash='fr4_cache/beamer/time_plots5_3913c00cbbb0de962d2653ee400d277e'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/time_plots5-1.pdf)\n:::\n:::\n\n\n## Data incidents by nature of incident\n\n\n::: {.cell hash='fr4_cache/beamer/time_plots6_e9650d8d029a8324b9a3df752992c3bc'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/time_plots6-1.pdf)\n:::\n:::\n\n\n## Data features\n\n\n::: {.cell hash='fr4_cache/beamer/data_features_7d70f32afa282f9444efd42c0f939d13'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/data_features-1.pdf)\n:::\n:::\n\n\n## Forecasting methods\n\n1. **Naïve**: Empirical distribution of past daily attended incidents.\n2. **ETS**: Exponential Smoothing State Space models.\n3. **GLM**: Poission Regression with spline trend, day of the week, annual Fourier seasonality, public holidays, school holidays, Christmas Day, New Year's Day.\n4. **TSGLM**: Poisson Regression with same covariates plus three autoregressive terms.\n5. **Ensemble**: Mixture distribution of 1--4.\n\n## Forecasting methods\n\n1. **Naïve**: Empirical distribution of past daily attended incidents.\n\n\\begin{block}{}\n\\centerline{$y_{T+h|T} \\sim \\text{Empirical}(y_{1},\\dots,y_{T})$}\n\\end{block}\\vspace*{1cm}\\pause\n\n2. **ETS**: Exponential Smoothing State Space models.\n\n\\begin{block}{}\n\\centerline{$y_{T+h|T} \\sim \\text{Normal}(\\hat{y}_{T+h|T},\\hat{\\sigma}^2_{T+h|T})$}\n\\end{block}\n\n## Forecasting methods\n\n3. **GLM**: Poission Regression\n\n\\begin{block}{}\n\\centerline{$y_{T+h|T} \\sim \\text{Poisson}(\\hat{y}_{T+h|T}) \\qquad\\text{where}\\qquad \\hat{y}_{T+h|T} = \\exp(\\bm{x}_{T+h}'\\bm{\\beta})$}\n\\end{block}\n\nand $\\bm{x}_{T+h}$ is a vector of covariates including\n\n\\begin{multicols}{2}\n\\begin{itemize}\\tightlist\n\\item spline trend\n\\item day of the week\n\\item annual Fourier seasonality\n\\item public holidays\n\\item school holidays\n\\item Christmas Day\n\\item New Year's Day\n\\end{itemize}\n\\end{multicols}\\vspace*{10cm}\n\n## Forecasting methods\n\\fontsize{9}{8}\\sf\\vspace*{-0.15cm}\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-26_ffad87a0538624fe58ccdb0f5ce0f582'}\n::: {.cell-output .cell-output-stdout}\n```\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     6.998511   0.017412  401.93  < 2e-16 ***\nSpline_1        0.027859   0.004740    5.88  4.2e-09 ***\nSpline_2       -0.088244   0.006394  -13.80  < 2e-16 ***\nSpline_3       -0.075036   0.004784  -15.68  < 2e-16 ***\nSpline_4       -0.111854   0.010202  -10.96  < 2e-16 ***\nSpline_5       -0.043009   0.004462   -9.64  < 2e-16 ***\nMonday          0.019147   0.003174    6.03  1.6e-09 ***\nTuesday        -0.016414   0.003180   -5.16  2.4e-07 ***\nWednesday      -0.015479   0.003184   -4.86  1.2e-06 ***\nThursday       -0.006804   0.003178   -2.14  0.03230 *  \nFriday          0.012235   0.003156    3.88  0.00011 ***\nSaturday        0.005293   0.003165    1.67  0.09438 .  \nFourier_S1_365  0.005365   0.001294    4.15  3.4e-05 ***\nFourier_C1_365  0.008263   0.001263    6.54  6.1e-11 ***\nFourier_S2_365  0.004235   0.001271    3.33  0.00086 ***\nFourier_C2_365 -0.010510   0.001216   -8.64  < 2e-16 ***\nFourier_S3_365 -0.000556   0.001275   -0.44  0.66303    \nFourier_C3_365  0.002650   0.001243    2.13  0.03294 *  \nPublic_holiday  0.033278   0.005697    5.84  5.2e-09 ***\nSchool_holiday  0.004857   0.002346    2.07  0.03843 *  \nXmas           -0.051902   0.016772   -3.09  0.00197 ** \nNew_years_day   0.120385   0.015573    7.73  1.1e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\\begin{textblock}{2.7}(12,3)\n\\fontsize{9}{9}\\sf\n\\begin{block}{\\fontsize{9}{9}\\sf\\centerline{Significance}}\n\\begin{tabular}{rl}\n\\verb|***| &$p < 0.001$\\\\\n\\verb|**| &$p < 0.01$\\\\\n\\verb|*| &$p < 0.05$\\\\\n\\verb|.| &$p < 0.1$\n\\end{tabular}\n\\end{block}\n\\end{textblock}\n\n## Forecasting methods\n\n4. **TSGLM**: Poisson Regression\n\n\\begin{block}{}\\vspace*{-0.8cm}\n\\begin{align*}\ny_{T+h|T} &\\sim \\text{Poisson}(\\hat{y}_{T+h|T}) \\\\\n\\text{where}\\qquad\n\\hat{y}_{T+h|T} &= \\exp\\Big(\\bm{x}_{T+h}'\\bm{\\beta} + \\sum_{k=1}^3 \\alpha_k \\log(y_{T+h-k}+1)\\Big)\n\\end{align*}\n\\end{block}\\vspace*{-0.3cm}\n\nand $\\bm{x}_{T+h}$ is a vector of covariates including\n\n\\begin{multicols}{2}\n\\begin{itemize}\\tightlist\n\\item spline trend\n\\item day of the week\n\\item annual Fourier seasonality\n\\item public holidays\n\\item school holidays\n\\item Christmas Day\n\\item New Year's Day\n\\end{itemize}\n\\end{multicols}\\vspace*{10cm}\n\n## Notation\n\n\\begin{textblock}{8.5}(0.2,1.5)\nEvery collection of time series with linear constraints can be written as\n\\centerline{\\colorbox[RGB]{210,210,210}{$\\bY_{t}=\\color{blue}\\bS\\color{red}\\bm{b}_{t}$}}\n\\vspace*{-0.9cm}\\begin{itemize}\\parskip=0cm\\itemsep=0cm\n\\item $\\by_t=$ vector of all series at time $t$\n\\item $ y_{\\text{Total},t}= $ aggregate of all series at time\n$t$.\n\\item $ y_{X,t}= $ value of series $X$ at time $t$.\n\\item $\\color{red}{\\bm{b}_t}=$ vector of most disaggregated series at time $t$\n\\item $\\color{blue}{\\bS}=$ ``summing matrix'' containing the linear constraints.\n\\end{itemize}\n\\end{textblock}\n\n\\begin{textblock}{5.7}(11.4,0.1)\n\\begin{minipage}{4cm}\n\\begin{block}{}\\centering\n\\begin{tikzpicture}\n\\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]\n\\tikzstyle[level distance=.3cm]\n\\tikzstyle[sibling distance=12cm]\n\\tikzstyle{level 1}=[sibling distance=10mm,font=\\small,set style={{every node}+=[fill=blue!15]}]\n\\node{Total}[edge from parent fork down]\n child {node {A}\n }\n child {node {B}\n }\n child {node {C}\n };\n\\end{tikzpicture}\n\\end{block}\n\\end{minipage}\n\\end{textblock}\n\n\\only<1>{\\begin{textblock}{5.7}(9.4,2.8)\\fontsize{14}{15}\\sf\n\\begin{align*}\n\\bY_{t}&= \\begin{pmatrix}\n  y_{\\text{Total},t}\\\\\n  y_{A,t}\\\\\n  y_{B,t}\\\\\n  y_{C,t}\n  \\end{pmatrix}  \\\\\n  &= {\\color{blue}\\underbrace{\\begin{pmatrix}\n                1 & 1 & 1 \\\\\n                1 & 0 & 0 \\\\\n                0 & 1 & 0\\\\\n                0 & 0 & 1\n                \\end{pmatrix}}_{\\bS}}\n     {\\color{red}\\underbrace{\\begin{pmatrix}\n       y_{A,t}\\\\y_{B,t}\\\\y_{C,t}\n       \\end{pmatrix}}_{\\bm{b}_{t}}}\n\\end{align*}\n\\end{textblock}}\n\\only<2>{\\begin{textblock}{5.7}(9.4,3.2)\\fontsize{14}{15}\\sf\n\\begin{alertblock}{}\n\\begin{itemize}\\itemsep=0.1cm\n\\item Base forecasts: $\\hat{\\bm{y}}_{T+h|T}$\n\\item Reconciled forecasts: $\\tilde{\\bm{y}}_{T+h|T}=\\bS\\bm{G}\\hat{\\bm{y}}_{T+h|T}$\n\\item MinT: $\\bG = (\\bS'\\bm{W}_h^{-1}\\bS)^{-1}\\bS'\\bm{W}_h^{-1}$ where $\\bm{W}_h$ is covariance matrix of base forecast errors.\n\\end{itemize}\n\\end{alertblock}\n\\end{textblock}}\n\n## Nonparametric bootstrap reconciliation\n\n* Fit model to all series and store the residuals as $\\underaccent{\\tilde}{\\bm{\\varepsilon}}_t$.\n* These should be serially uncorrelated but cross-sectionally correlated.\n* Draw iid samples from $\\underaccent{\\tilde}{\\bm{\\varepsilon}}_1,\\dots,\\underaccent{\\tilde}{\\bm{\\varepsilon}}_T$ with replacement.\n* Simulate future sample paths for model using the bootstrapped residuals.\n* Reconcile each sample path using MinT.\n* Combine the reconciled sample paths to form a mixture distribution at each forecast horizon.\n\n## Performance evaluation\n\n* Ten-fold time series cross-validation\n* Forecast horizon of 1--84 days\n* Each training set contains an additional 42 days.\n* Forecasts at 43--84 days correspond to planning horizon.\n\n\n::: {.cell hash='fr4_cache/beamer/cv1_0edd941bc4403a686935c4fb6a13489c'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/cv1-1.pdf)\n:::\n:::\n\n\n## Performance evaluation\n\n\\vspace*{0.2cm}\\begin{block}{}\n\\centerline{$\\text{MASE} = \\text{mean}(|q_{j}|)$}\n$$\n  q_{j} = \\frac{e_{j}\\phantom{^2}}\n {\\displaystyle\\frac{1}{T-m}\\sum_{t=m+1}^T |y_{t}-y_{t-m}|}\n$$\n\\end{block}\n\n* $y_t=$ observation for period $t$\n* $e_{j}=$ forecast error for forecast horizon $j$\n* $T=$ size of training set\n* $m = 7$\n\n\\vspace*{10cm}\n\n## Performance evaluation\n\n\\vspace*{0.2cm}\\begin{block}{}\n\\centerline{$\\text{MSSE} = \\text{mean}(q_{j}^2)$}\n$$\n  q^2_{j} = \\frac{ e^2_{j}}\n {\\displaystyle\\frac{1}{T-m}\\sum_{t=m+1}^T (y_{t}-y_{t-m})^2}\n$$\n\\end{block}\n\n* $y_t=$ observation for period $t$\n* $e_{j}=$ forecast error for forecast horizon $j$\n* $T=$ size of training set\n* $m = 7$\n\n\\vspace*{10cm}\n\n## Performance evaluation\n\n\\vspace*{0.2cm}\\begin{block}{}\n\\centerline{$\\text{CRPS} = \\text{mean}(p_j)$}\n$$\n  p_j = \\int_{-\\infty}^{\\infty} \\left(G_j(x) - F_j(x)\\right)^2dx,\n$$\n\\end{block}\n\n* $G_j(x)=$ forecast distribution for forecast horizon $j$\n* $F_j(x)=$ true distribution for same period\n\n\\vspace*{10cm}\n\n\n\n\n\n\n## Forecast accuracy\n\n\n::: {.cell hash='fr4_cache/beamer/results_graph_5be1d9bf5dde074b530a846ca011b1f8'}\n::: {.cell-output-display}\n![](fr4_files/figure-beamer/results_graph-1.pdf)\n:::\n:::\n\n\n## Forecast accuracy: 43--84 days ahead\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/results_table_msse_5a076b0e415a28fce66286c0e3002cf9'}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\\centering\n\\begin{tabular}[t]{llrrrr}\n\\toprule\n\\multicolumn{2}{c}{ } & \\multicolumn{4}{c}{MSSE} \\\\\n\\cmidrule(l{3pt}r{3pt}){3-6}\nMethod & Model & Total & Control areas & Health boards & Bottom\\\\\n\\midrule\nBase & Naïve & 1.169 & 1.056 & 1.062 & 1.031\\\\\nBase & ETS & 0.979 & 0.875 & 0.816 & \\textbf{0.975}\\\\\nBase & GLM & 0.813 & 0.897 & 0.875 & 1.009\\\\\nBase & TSGLM & 0.822 & 0.901 & 0.875 & 1.050\\\\\nBase & Ensemble & 0.599 & 0.729 & 0.774 & 0.993\\\\\n\\addlinespace\nMinT & Naïve & 1.168 & 1.057 & 1.062 & 2.095\\\\\nMinT & ETS & 0.785 & 0.852 & 0.845 & 0.994\\\\\nMinT & GLM & 0.720 & 0.827 & 0.837 & 1.803\\\\\nMinT & TSGLM & 0.722 & 0.833 & 0.839 & 1.851\\\\\nMinT & Ensemble & \\textbf{0.560} & \\textbf{0.706} & \\textbf{0.765} & 1.557\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n## Forecast accuracy: 43--84 days ahead\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/results_table_mase_5f627ac3ce047d12c4fd1718a9382775'}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\\centering\n\\begin{tabular}[t]{llrrrr}\n\\toprule\n\\multicolumn{2}{c}{ } & \\multicolumn{4}{c}{MASE} \\\\\n\\cmidrule(l{3pt}r{3pt}){3-6}\nMethod & Model & Total & Control areas & Health boards & Bottom\\\\\n\\midrule\nBase & Naïve & 1.139 & 1.059 & 1.047 & 1.019\\\\\nBase & ETS & 0.963 & 0.930 & 0.899 & 1.038\\\\\nBase & GLM & 0.910 & 0.940 & 0.923 & \\textbf{1.002}\\\\\nBase & TSGLM & 0.911 & 0.939 & 0.924 & 1.005\\\\\nBase & Ensemble & 0.782 & 0.856 & 0.876 & 1.008\\\\\n\\addlinespace\nMinT & Naïve & 1.138 & 1.059 & 1.047 & 2.651\\\\\nMinT & ETS & 0.877 & 0.916 & 0.915 & 1.289\\\\\nMinT & GLM & 0.848 & 0.901 & 0.902 & 2.493\\\\\nMinT & TSGLM & 0.852 & 0.903 & 0.903 & 2.513\\\\\nMinT & Ensemble & \\textbf{0.753} & \\textbf{0.844} & \\textbf{0.872} & 2.260\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n## Forecast accuracy: 43--84 days ahead\n\\fontsize{10}{10}\\sf\n\n\n::: {.cell hash='fr4_cache/beamer/unnamed-chunk-32_699c6182627f8ca45e135cb7b8a2f5ea'}\n::: {.cell-output-display}\n\\begin{table}[!h]\n\\centering\n\\begin{tabular}[t]{llrrrr}\n\\toprule\n\\multicolumn{2}{c}{ } & \\multicolumn{4}{c}{CRPS} \\\\\n\\cmidrule(l{3pt}r{3pt}){3-6}\nMethod & Model & Total & Control areas & Health boards & Bottom\\\\\n\\midrule\nBase & Naïve & 30.387 & 10.882 & 5.500 & 0.302\\\\\nBase & ETS & 14.309 & 6.074 & 3.476 & 0.244\\\\\nBase & GLM & 15.396 & 6.253 & 3.576 & 0.244\\\\\nBase & TSGLM & 15.316 & 6.227 & 3.575 & 0.245\\\\\nBase & Ensemble & 12.978 & \\textbf{5.727} & 3.430 & 0.243\\\\\n\\addlinespace\nMinT & Naïve & 30.368 & 10.902 & 5.498 & 0.313\\\\\nMinT & ETS & 13.515 & 5.967 & 3.547 & \\textbf{0.243}\\\\\nMinT & GLM & 13.839 & 5.917 & 3.453 & 0.246\\\\\nMinT & TSGLM & 14.000 & 5.947 & 3.455 & 0.248\\\\\nMinT & Ensemble & \\textbf{12.585} & 5.728 & \\textbf{3.426} & 0.247\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n:::\n:::\n\n\n## Conclusions\n\n* Ensemble mixture distributions give better forecasts than any component methods.\n* Forecast reconciliation improves forecast accuracy, even when some component methods are quite poor.\n* Forecast reconciliation allows coordinated planning and resource allocation.\n\n\n# Bayesian versions\n\n## Bayesian versions\n\n@novetal2017\n\nAnother strain of the literature brings a Bayesian approach to the regression model interpretation of forecast reconciliation. @novetal2017 recognise that the posterior of ${\\bm\\beta}_{h}$ can act as a probabilistic forecast for the bottom-level series. Using Markov chain Monte Carlo to obtain a sample from this posterior, and then aggregating, gives a probabilistic forecast for the entire hierarchy.\n\n## Bayesian versions\n\n@swissexports also obtain a posterior on ${\\bm\\beta}_{h}$, but their focus is on augmenting the reconciliation regression equation with a vector of intercepts that allow for base forecasts to be biased and evolve according to a state space representation.\n\nJudgement can be incorporated via the prior, in the latter case via an explicit empirical example where prior information about a structural break in data classification can be exploited. Also, while both papers recognise the potential of Bayesian inference to obtain probabilistic forecasts, neither paper makes this the focus of empirical evaluation. @novetal2017 minimise loss functions over the posterior sample and then use this as a point forecast, while @swissexports use maximum a posteriori (MAP) estimates as point forecasts.\n\n## Bayesian versions\n\n@CorEtAl2021 In particular, a prior is placed on the bottom-level series with the mean set to point forecasts obtained in the first step of forecast reconciliation and a variance given by the variance-covariance matrix of one-step ahead errors. This prior is updated using the top-level forecasts obtained in the first stage of forecast reconciliation via Bayes' rule. The method generalises MinT in the sense that the posterior mean is equivalent to the usual MinT approach. The necessary updates via Bayes' rule have parallels with the Kalman filter since the reconciliation problem is recast as a linear Gaussian model. The empirical results are evaluated using scoring rules for probabilistic forecasts including the CRPS and energy score. This approach has also recently been extending to the challenging case of forecast reconciliation for discrete data by @CorEtAl2022 and @Zambon2022.\n\n## Thanks!\n\n\\placefig{0}{1.4}{trim = 10 45 0 0, clip=TRUE, width=10cm, height=2.5cm}{roman}\n\\placefig{2}{1.4}{trim = 20 20 0 0, clip=TRUE, width=10cm, height=2.7cm}{george}\n\\placefig{4}{1.4}{trim = 0 10 0 0, clip=TRUE, width=10cm, height=2.5cm}{hanlin}\n\\placefig{6}{1.4}{trim = 10 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{earowang}\n\\placefig{8}{1.4}{trim = 0 15 0 0, clip=TRUE, width=10cm, height=2.5cm}{alanlee}\n\\placefig{10}{1.4}{trim = 30 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{mitch}\n\\placefig{12}{1.4}{trim = 15 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{shanika}\n\\placefig{14}{1.4}{trim = 40 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{tas}\n\n\\placefig{0}{3.9}{trim = 30 10 30 0, clip=TRUE, width=10cm, height=2.5cm}{puwasala}\n\\placefig{2}{3.9}{trim = 0 10 0 0, clip=TRUE, width=10cm, height=2.5cm}{fotios}\n\\placefig{4}{3.9}{trim = 100 30 50 20, clip=TRUE, width=10cm, height=2.5cm}{nikos}\n\\placefig{6}{3.9}{trim = 50 30 0 0, clip=TRUE, width=10cm, height=2.5cm}{souhaib}\n\\placefig{8}{3.9}{trim = 110 40 50 0, clip=TRUE, width=10cm, height=2.5cm}{james}\n\\placefig{10}{3.9}{trim = 40 40 0 0, clip=TRUE, width=10cm, height=2.5cm}{mahdi}\n\\placefig{12}{3.9}{trim = 50 50 0 0, clip=TRUE, width=10cm, height=2.5cm}{christoph}\n\\placefig{14}{3.9}{trim = 50 50 0 20, clip=TRUE, width=10cm, height=2.5cm}{fin}\n\n\\placefig{0}{6.4}{trim = 10 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{berwin}\n\\placefig{2}{6.4}{trim = 10 20 0 0, clip=TRUE, width=10cm, height=2.5cm}{galit}\n\\placefig{4}{6.4}{trim = 10 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{mahsa}\n\\placefig{6}{6.4}{trim = 10 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{florian}\n\\placefig{8}{6.4}{trim = 30 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{evan}\n\\placefig{10}{6.4}{trim = 5 5 0 0, clip=TRUE, width=10cm, height=2.5cm}{vassilis}\n\\placefig{12}{6.4}{trim = 90 0 0 0, clip=TRUE, width=10cm, height=2.5cm}{carla}\n\\placefig{14}{6.4}{trim = 0 40 0 0, clip=TRUE, width=10cm, height=2.5cm}{pablo}\n\n## More information\n\\fontsize{18}{20}\\sf\n\n * Slides and papers: **robjhyndman.com**\n * Packages: **tidyverts.org**\n * Forecasting textbook using fable package: **OTexts.com/fpp3**\n\n\\begin{textblock}{8}(7.6,4.8)\n\\begin{alertblock}{Find me at ...}\n\\href{https://twitter.com/robjhyndman}{\\faicon{twitter} @robjhyndman}\n\n\\href{https://github.com/robjhyndman}{\\faicon{github}  @robjhyndman}\n\n\\href{https://robjhyndman.com}{\\faicon{home} robjhyndman.com}\n\n\\href{mailto:rob.hyndman@monash.edu}{\\faicon{envelope}  rob.hyndman@monash.edu}\n\\end{alertblock}\n\\end{textblock}\n\\vspace*{10cm}\n\n\n\\nocite{ctprob,smartmeterhts,coherentprob,swissexports}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}